{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for papers in category Economics\n",
      "Searching for papers in subcategory econ.GN\n",
      "Extracting ecai_submission.tex\n",
      "Preprocessing GN_paper_0.tex: \n",
      "Title, abstract or \\maketitle not found.\n",
      "Error extracting ./tarfiles/paper_1.tar.gz: not a gzip file\n",
      "Extracting ms.tex\n",
      "Preprocessing GN_paper_2.tex: \n",
      "Preprocessed text is too long: 36561 tokens\n",
      "Error extracting ./tarfiles/paper_3.tar.gz: not a gzip file\n",
      "Extracting Manuscript.tex\n",
      "Preprocessing GN_paper_4.tex: \n",
      "Title, abstract or \\maketitle not found.\n",
      "Paper 5 has 3 tex files. Skipping.\n",
      "Paper 6 has 3 tex files. Skipping.\n",
      "Extracting main.tex\n",
      "Preprocessing GN_paper_7.tex: \n",
      "ChatCompletion(id='chatcmpl-9LtVoegOfn7DjGKtys7yRKjFNaXkQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I can't detect the origin of this paper.\", role='assistant', function_call=None, tool_calls=None))], created=1715005304, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_a450710239', usage=CompletionUsage(completion_tokens=10, prompt_tokens=10532, total_tokens=10542))\n",
      "GPT Answer: I can't detect the origin of this paper.\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 66] Directory not empty: './tarfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremovedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SocialComputing/lib/python3.9/os.py:243\u001b[0m, in \u001b[0;36mremovedirs\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremovedirs\u001b[39m(name):\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"removedirs(name)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Super-rmdir; remove a leaf directory and all empty intermediate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m     \u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     head, tail \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(name)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tail:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 66] Directory not empty: './tarfiles'"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import os\n",
    "import tarfile\n",
    "import preprocess_paper as preprocessor\n",
    "import time\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "def search_cat(cat, tmpdir, dirpath, required_papers=10):\n",
    "    search = arxiv.Search(\n",
    "    query = f\"cat:{cat}\",\n",
    "    sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    successful_downloads = 0\n",
    "\n",
    "    for i,r in enumerate(client.results(search)):\n",
    "        filename = f\"paper_{i}.tar.gz\"\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            filepath = r.download_source(dirpath=tmpdir, filename=filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading Paper {i}: {e}\")\n",
    "            continue\n",
    "        successful_extract = False\n",
    "        tex_path = os.path.join(dirpath, f'{cat.split(\".\")[1]}_paper_{i}.tex')\n",
    "        try:\n",
    "            with tarfile.open(filepath, 'r:gz') as tar:\n",
    "                files = tar.getmembers()\n",
    "                tex_files = [f.name for f in files if f.name.endswith('.tex')]\n",
    "                if len(tex_files) == 1:\n",
    "                    tex_file = tex_files[0]\n",
    "                    print(f\"Extracting {tex_file}\")\n",
    "                    tar.extract(tex_file, path=dirpath)\n",
    "                    os.rename(os.path.join(dirpath, tex_file), tex_path)\n",
    "                    successful_extract = True\n",
    "                else:\n",
    "                    print(f\"Paper {i} has {len(tex_files)} tex files. Skipping.\")\n",
    "                tar.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {filepath}: {e}\")\n",
    "        os.remove(filepath)\n",
    "\n",
    "        if successful_extract:\n",
    "            try:\n",
    "                successful_pp = preprocessor.preprocess(tex_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error preprocessing {tex_path}: {e}\")\n",
    "                successful_pp = False\n",
    "            \n",
    "            if successful_pp:\n",
    "                successful_downloads += 1\n",
    "            else:\n",
    "                os.remove(tex_path)\n",
    "\n",
    "        if successful_downloads == required_papers:\n",
    "            break\n",
    "\n",
    "    return successful_downloads\n",
    "\n",
    "\n",
    "# Arxiv categories\n",
    "cats = {\n",
    "    # 'Computer Science': ['cs.' + cat for cat in [\n",
    "    #     'AI', 'AR', 'CC', 'CE', 'CG', 'CL', 'CR', 'CV', 'CY', 'DB',\n",
    "    #     'DC', 'DL', 'DM', 'DS', 'ET', 'FL', 'GL', 'GR', 'GT', 'HC',\n",
    "    #     'IR', 'IT', 'LG', 'LO', 'MA', 'MM', 'MS', 'NA', 'NE', 'NI',\n",
    "    #     'OH', 'OS', 'PF', 'PL', 'RO', 'SC', 'SD', 'SE', 'SI', 'SY',\n",
    "    # ]],\n",
    "    # 'Mathematics': ['math.' + cat for cat in [\n",
    "    #     'AT', 'CA', 'CO', 'CT', 'CV', 'DG', 'DS', 'FA',\n",
    "    #     'GM', 'GN', 'GR', 'GT', 'HO', 'IT', 'KT', 'LO', 'MG', 'MP',\n",
    "    #     'NA', 'NT', 'OA', 'OC', 'PR', 'QA', 'RT', 'RA', 'SP', 'ST',\n",
    "    # ]],\n",
    "    # 'Quantitative Finance': ['q-fin.' + cat for cat in [\n",
    "    #     'CP', 'EC', 'GN', 'MF', 'PM', 'PR', 'RM', 'ST', 'TR',\n",
    "    # ]],\n",
    "    # 'Statistics': ['stat.' + cat for cat in [\n",
    "    #     'AP', 'CO', 'ME', 'ML', 'OT', 'TH',\n",
    "    # ]],\n",
    "    'Economics': ['econ.' + cat for cat in ['GN']],\n",
    "}\n",
    "tmpdir = './tarfiles'\n",
    "\n",
    "if not os.path.exists(tmpdir):\n",
    "    os.makedirs(tmpdir)\n",
    "\n",
    "for cat, subcats in cats.items():\n",
    "    dirpath = f'./selected_papers/{cat}'\n",
    "    required_papers = 1\n",
    "\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    print(f\"Searching for papers in category {cat}\")\n",
    "    for subcat in subcats:\n",
    "        print(f\"Searching for papers in subcategory {subcat}\")\n",
    "        required_papers -= search_cat(subcat, tmpdir, dirpath, required_papers=required_papers)\n",
    "        if required_papers == 0:\n",
    "            break\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    time.sleep(5)\n",
    "\n",
    "os.removedirs(tmpdir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SocialComputing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
