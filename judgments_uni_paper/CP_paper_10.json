{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Switzerland","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"ETH Zurich","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{ETH Zurich, Switzerland}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 9\n3. Credibility: 7\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 8\n8. Overall score: 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Switzerland","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Lausanne","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Lausanne, Switzerland}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 8\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Switzerland","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Zurich University of Applied Sciences (ZHAW)","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Zurich University of Applied Sciences (ZHAW), Switzerland}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 8\n3. Credibility: 9\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"England","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Cambridge","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Cambridge, England}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 8\n3. Credibility: 8\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"England","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Dundee","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Dundee, England}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 7\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"England","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Wolverhampton","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Wolverhampton, England}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 7\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"China","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Peking University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Peking University, China}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 8\n2. Method 9\n3. Credibility 8\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 9\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"China","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Dalian University of Technology","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Dalian University of Technology, China}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 8\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"China","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"China University of Mining and Technology","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{China University of Mining and Technology, China}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 7\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n\nOverall score: 8.3"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"India","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Indian Institute of Technology Bombay (IITB)","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Indian Institute of Technology Bombay (IITB), India}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 8\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"India","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Delhi","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Delhi, India}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.75"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"India","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Indian Institute of Technology Hyderabad (IITH)","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Indian Institute of Technology Hyderabad (IITH), India}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Iran","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Sharif University of Technology","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Sharif University of Technology, Iran}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 7\n2. Method: 8\n3. Credibility: 9\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.0"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Iran","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Shiraz University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Shiraz University, Iran}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 7\n4. Understandability 9\n5. Relevance 8\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Iran","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Ferdowsi University of Mashhad","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Ferdowsi University of Mashhad, Iran}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 8\n2. Method 9\n3. Credibility 9\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 9\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"USA","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Massachusetts Institute of Technology","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Massachusetts Institute of Technology, USA}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 9\n3. Credibility: 9\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 9"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"USA","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Houston","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Houston, USA}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 10\n2. Method 9\n3. Credibility 9\n4. Understandability 8\n5. Relevance 10\n6. Quality of Citations 9\n7. Linguistic style and soundness of grammar 9\n8. Overall score 9.0"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"USA","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Western Washington University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Western Washington University, USA}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 9\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 9\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.75"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Brazil","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Sao Paulo","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Sao Paulo, Brazil}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.75"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Brazil","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Universidade de Bras\u00edlia","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Universidade de Bras\u00edlia, Brazil}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 7\n5. Relevance: 9\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 8\n8. Overall score: 8.25"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Brazil","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Pontif\u00edcia Universidade Cat\u00f3lica do Rio Grande do Sul, PUCRS","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Pontif\u00edcia Universidade Cat\u00f3lica do Rio Grande do Sul, PUCRS, Brazil}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 8\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Egypt","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Cairo University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Cairo University, Egypt}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 10\n2. Method: 10\n3. Credibility: 9\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 9"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Egypt","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Alexandria University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Alexandria University, Egypt}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 10\n2. Method: 10\n3. Credibility: 9\n4. Understandability: 10\n5. Relevance: 10\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 10\n8. Overall score: 9.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Egypt","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Zagazig University","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Zagazig University, Egypt}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 8\n2. Method 9\n3. Credibility 9\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Australia","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"The University of Melbourne","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{The University of Melbourne, Australia}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 7\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 8\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Australia","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"The University of Adelaide","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{The University of Adelaide, Australia}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 10\n2. Method: 10\n3. Credibility: 9\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 9"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Australia","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Queensland University of Technology (QUT)","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Queensland University of Technology (QUT), Australia}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 9\n3. Credibility: 9\n4. Understandability: 8\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Germany","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Technical University of Munich","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Technical University of Munich, Germany}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 10\n2. Method 9\n3. Credibility 8\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 9"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Germany","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Potsdam","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Potsdam, Germany}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 9\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 9\n6. Quality of Citations: 8\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"Germany","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"Leibniz University Hannover","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{Leibniz University Hannover, Germany}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 9\n3. Credibility 8\n4. Understandability 9\n5. Relevance 9\n6. Quality of Citations 9\n7. Linguistic style and soundness of grammar 9\n8. Overall score 9"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"South Africa","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of Cape Town","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of Cape Town, South Africa}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 8\n2. Method 9\n3. Credibility 9\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 9\n8. Overall score 8.5"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"South Africa","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of South Africa","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of South Africa, South Africa}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality 9\n2. Method 8\n3. Credibility 7\n4. Understandability 8\n5. Relevance 9\n6. Quality of Citations 8\n7. Linguistic style and soundness of grammar 8\n8. Overall score 8.25"}
{"title":"CP_paper_10","field":"Quantitative Finance","country_association":"South Africa","uni_association":null,"paper_ltx":"\\begin{document}\n\\affiliation{$$_affiliation_$$}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","input_length":11359,"university_association":"University of the Free State","rating_prompt":"Rate the quality of the paper according to the following criterias on a scale from 1 (worst) to 10 (best). Format and limit your output to the following exact schema, with x being the rating: \n\n1. Originality x\n2. Method x\n3. Credibility x\n4. Understandability x\n5. Relevance x\n6. Quality of Citations x\n7. Linguistic style and soundness of grammar x\n8. Overall score x\n\n\n\n\\begin{document}\n\\affiliation{University of the Free State, South Africa}\n\\title{On Risk-Sensitive\nDecision  \\\\ Making Under Uncertainty}\n\\maketitle\n\t\\thispagestyle{empty}\n\t\\pagestyle{empty}\n\t\n\t\n\\begin{abstract} \n    This paper studies a {\\em risk-sensitive} decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.\n\\end{abstract}\n\t\n\\vspace{3mm}\n\\begin{IEEEkeywords}\nStochastic Systems, Decision Making Under Uncertainty, Risk-Sensitive Optimization, Variance Regularization. \n\\end{IEEEkeywords}\n\t\n\t\n\\section{Introduction}\\label{section: introduction}\nOptimal decision-making under uncertainty is critical across various disciplines, including engineering, management, economics, and finance. The standard approach to addressing this issue is by applying expected utility theory, which formulates the problem as stochastic programming; see \\cite{shapiro2021lectures, bertsekas2012dynamic}.\n\n\nEarly paradigms for this type of problem include expected utility theory in \\cite{von2007theory}, the Markowitz mean-variance portfolio optimization \\cite{Markowitz_1952},  Kelly's criterion \\cite{Kelly_1956, thorp2006kelly}, and the prospect theory~\\cite{kahneman1979prospect}. Subsequent studies have explored different aspects of this topic. For instance, \\cite{kuhn2010analysis} analyzed the rebalancing frequency in log-optimal portfolio selection, \\cite{wu2020analysis} examined the Kelly betting problem in a finite stage framework. Studies by \\cite{luenberger1993preference, luenberger2013investment} investigated the foundations of using Expected Logarithmic Growth (ELG) and the variance of logarithmic growth as preferences in portfolio management problems. \n\n\nFurther studies by \\cite{algoet1988asymptotic, cover2006elements} delved into ELG portfolios and derived various optimalities. More recently, \\cite{hsieh2020necessary, hsieh2023asymptotic} explored the frequency-dependent log-optimal portfolio and its asymptotic log-optimality. Then\n\\cite{wong2023frequency} studied the frequency-dependent log-optimal portfolio problems with costs. A nonlinear control theoretic approach is considered in \\cite{proskurnikov2023benefit}.\nHowever, these studies largely omitted an explicit focus on \\textit{risk} within the optimization goal.\n\n\nTo this end, this paper studies a class of \\textit{risk-sensitive} decision-making problems under uncertainty. The objective is composed of expected log-growth and variance of log-growth of the decision maker's account.\nWe consider a decision-making process that unfolds over a fixed number of stages, where a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's accumulated value is updated at each stage based on the chosen alternatives. This problem is modeled as a stochastic control problem, aimed at maximizing a risk-sensitive objective function. \nFurthermore, the paper provides the necessary optimality conditions for this problem.\n\n\n\n\n The rest of the paper is organized as follows. Section~\\ref{section: problem formulation} provides the problem formulation for the risk-sensitive decision-making problem. Section~\\ref{section: main results} first presents an equivalent optimization problem.\nThen we provide rigorous proof for the necessary condition for the optimality of the problem. Subsequently, Section~\\ref{section: Illustrative Examples} illustrates the optimality result with several numerical examples. Finally, Section~\\ref{section: Concluding Remarks} provides concluding remarks and outlines potential future research directions.\n\n\n \n\t\n \n\\section{Problem Formulation}\\label{section: problem formulation}\t\nConsider a decision maker engaged in a decision-making process that unfolds over a fixed number of stages, denoted by $N>1$. \nFor $k=0,1,\\dots, N-1$, a decision maker chooses among~$m \\geq 2$ alternatives, with one being a deterministic option with a nonnegative payoff $r(k) \\geq 0.$ That is, the outcome is certain and is treated as a degenerate random variable with value $r(k)$ for all $k$ with probability one. \nAlternatively, if the~$i$th alternative is stochastic, we take~$X_i(k)$ as the random payoffs.\nWe assume that the payoff vectors~$\nX(k):=\\left[ X_1(k), \\, X_2(k),\\,  \\dots, \\,X_m(k) \\right]^\\top \n$\nare i.i.d. and have a known distribution and have components $X_i(\\cdot)$ which can be arbitrarily correlated. \nThese vectors have components satisfying\n$\nX_{\\min,i}  \\leq X_i(k) \\leq X_{\\max,i}\n$\nwith predefined limits, where $-1 < X_{\\min,i} < 0 < X_{\\max,i} < 1$.\n\n\n\\subsection{Notation}\n    Throughout the paper, we take $\\mathbb{R}$ to be the set of real numbers and $\\mathbb{R}_{+}$ to be the set of nonnegative real numbers.\n    We denote by $\\textbf{1}$ the vector with all components to be equal to~$1$ and denote by $ e_i \\in \\mathbb{R}^m $ to be the unit vector having~1 at the~$i$th component.\n    All random objects are defined in a probability space~$(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ being the sample space,~$\\mathcal{F}$ being the information set, and $\\mathbb{P}$ being the probability measure. \n    For~$a,b \\in \\mathbb{R}^n$, the term $\\langle a, b \\rangle$ means the standard inner product~$a^\\top b$.\n\n\n\n\\subsection{Linear Decision Policy}\nTake $V(k)$ to be the decision maker's accumulated value and the $i$th feedback gain \n\t$\n    K_i(k) \\in [0, 1]\n\t$\nrepresents the fraction of the account allocated to the~$i$th asset for~$i=1,\\dots,m$. \nSaid another way,  the~$i$th controller is  a linear feedback of the form~$\n\tu_i(k) = K_i(k) V(k).\n\t$\nFor each $k$, we take $K_i(k) := K_i$ and impose a unit simplex constraint\n\t$$\n\tK \\in {\\mathcal K} := \\left\\{K \\in \\mathbb{R}^{m}: K_i \\geq 0 \\text{ for all $i$}, \\; K^\\top \\textbf{1} = 1 \\right\\}\n\t$$\n which is readily verified as a convex set. \n\n\n\n\n\\subsection{Value Dynamics} \n    Letting $n \\geq 1$ be the number of steps between decisions,  at time~{$k=0$}, the decision-maker begins with initial account~$V_0 := V(0)$ and initial investment control~{$\n\tu(0) = \\sum_{i=1}^m K_i V_0\n\t$}\n\tand waits~$n$ steps. Then, when~{$k=n$}, the control is updated to be~$\n\t\tu(n) = \\sum_{i=1}^m K_i V(n).\n\t\t$\n\t\n\nThe decision-maker starts with an initial accumulated value~$V(0)>0$. At each stage, the decision-maker chooses to allocate a fraction of the accumulated value to each of the~$m$ alternatives. This allocation is represented by the control gain~$K$, where each $K_i$ is the fraction of the accumulated value allocated to the $i$th alternative.\nFor decision period~$n \\geq 1$, the corresponding account value at stage $n$ is described by the stochastic recursion\n\t$\n\tV(n) =  \\langle K, \\mathcal{R}_n \\rangle V_0 \n\t$\nwhere $\\langle K, \\mathcal{R}_n \\rangle$ represents the total return from all alternatives at stage $n$ with the random vector $\\mathcal{R}_n$ having the $i$th component \n\t$$\n\t\\mathcal{R}_{n,i} := \\prod_{k=0}^{n-1} (1+X_i(k)) \n\t$$\n for $i=1,2, \\ldots, m$.\nIt is readily seen that~{$\\mathcal{R}_{n,i} > 0$} for all~$n \\geq 1$.\nIn the sequel, we may sometimes write $V(n; K)$ to emphasize the dependence on the feedback gain $K$. \n\n\n \n\n\n\\subsection{Risk-Sensitive Decision Making Problem}\nFor any decision period~$n \\geq 1$, we consider a  \\textit{risk-sensitive} objective function,\\footnote{In finance, a utility function $U$ is said to be \\textit{risk-averse} if it is concave, continuous, and strictly increasing; see \\cite{luenberger2013investment}. } see \\cite{luenberger1993preference}, as follows:\nTake\n\\begin{align} \\label{eq: risk-sensitive objective}\n\t{U_n^\\rho}(K; X) \n\t&:= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n; K)}{V_0} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n; K)}{V_0} \\right)\n\\end{align}\nwhere $\\rho \\geq 0$ is the \\textit{risk-aversion} constant, which modulates the degree of risk sensitivity, with higher values of $\\rho$ indicating a greater aversion to risk.\nOur goal is to solve the following stochastic control problem parameterized by feedback gain $K$:\n\\begin{align} \\label{problem: stochastic optimal control problem}\n    \\begin{aligned}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\nwith $\\mathcal{R}_n = [\\mathcal{R}_{n,1}, \\dots, \\mathcal{R}_{n,m}]^\\top$ with $ \\mathcal{R}_{n,i} = \\prod_{k=0}^{n - 1} ( 1 + X_i(k) ) $ for $i \\in \\{1, 2, \\dots, m \\}$.\nThat is, the decision-maker must balance the expected logarithmic return against the risk, represented by the variance of the logarithmic return.\n\n\\begin{remark}\\rm\n    It should be noted that Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex since the log-variance quantity may not be convex. However, if the risk-aversion constant~$\\rho =0$, then Problem~\\eqref{problem: stochastic optimal control problem} reduces to the classical expected log-growth maximization problem, which generally forms a concave program; see \\cite{maclean2011kelly,hsieh2023asymptotic}. Later in Section~\\ref{section: Illustrative Examples}, we shall demonstrate some cases where the log-variance is indeed convex.\n\\end{remark}\n\n\n\\section{Main Results}\\label{section: main results}\nThis section first presents an equivalent problem and then provides the necessary conditions for the optimality of the problem.\n Indeed, the next lemma simplifies Problem~\\eqref{problem: stochastic optimal control problem}.\n\n\\begin{lemma} \\label{lemma: equivalent risk-sensitive problem}\nFor $n\\geq 1$,\n    the risk-sensitive objective function~$U_n^\\rho(K; X)$   satisfies\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle  \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log\\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2.\n\\end{align*} \n\\end{lemma}\n\n\\begin{proof}\nWe shall proceed with a straightforward calculation.\nNote that\n    \\begin{align*}\n\t{U_n^\\rho}(K; X) \n\t&= \\frac{1}{n} \\mathbb{E}\\left[ \\log \\frac{V(n)}{V(0)} \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\frac{V(n)}{V(0)} \\right)  \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\text{var}\\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right) \\\\\n\t&= \\frac{1}{n}\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] - \\frac{\\rho}{2n^2}\\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle \\right)^2 \\right] \\\\\n\t&\\qquad + \\frac{\\rho}{2n^2}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2,\n\\end{align*}\nwhich is desired.\n\\end{proof}\n\n\n \n\n\nWhile Problem~\\eqref{problem: stochastic optimal control problem} may be nonconvex, see Appendix, the following lemma indicates that the necessary condition for optimality is possible to establish.\n\n\n\n \n\\begin{lemma}[Necessary Optimality Conditions] \\label{Lemma: risk term}\n    If the feedback vector $K^* \\in \\mathcal{K}$ is optimal to the stochastic control problem\n\\begin{align} \n    \\begin{aligned} \\label{problem: risk-sensitive problem}\n        &\\sup_{K \\in \\mathcal{K}}\\; U_n^\\rho (K; X)\\\\\n        &{\\rm s.t. } \\; V(n) = \\langle K, \\mathcal{R}_n \\rangle V_0 \n    \\end{aligned}\n\\end{align}\n    then for~$i=1,2,\\ldots,m$, we have\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{ \\mathcal{R}_{n,i} }{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        & +\\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] = 1, \\text{ if $K_i^* > 0$ }\n    \\end{align*}\n    \\begin{align*}\n         & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n\\rangle} \\right] \\\\\n        & +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\leq 1, \\text{ if $K_i^* = 0$. }\n    \\end{align*}\n\\end{lemma}\n\n\n\\begin{proof}\n  With the aid of Lemma~\\ref{lemma: equivalent risk-sensitive problem},  we rewrite Problem~\\eqref{problem: risk-sensitive problem} as an equivalent constrained minimization problem described as follows:\n    \\begin{align*}\n        &\\min_{K} -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E}\\left[ (\\log \\langle K, \\mathcal{R}_n \\rangle )^2 \\right] \\\\\n        &\\qquad   -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right]\\right)^2 \\\\\n        &{\\rm s. t.} \\; K^\\top  \\mathbf{1} - 1 = 0; \\\\\n        &\\;\\;\\;\\;\\; -K^\\top  e_i \\leq 0, \\; i=1,2, \\ldots, m\n    \\end{align*}\n    where $ e_i \\in \\mathbb{R}^m $ is unit vector having 1 at the $i$th component. Consider the Lagrangian\n    \\begin{align*}\n        \\mathcal{L}(K, \\lambda, \\mu)\n        &:= -\\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{2n} \\mathbb{E} \\left[ ( \\log \\langle K, \\mathcal{R}_n \\rangle)^2 \\right] \\\\\n        &\\qquad -\\frac{\\rho}{2n}\\left( \\mathbb{E}\\left[ \\log \\langle K, \\mathcal{R}_n \\rangle \\right] \\right)^2 \\\\ & \\qquad + \\lambda (K^\\top  \\mathbf{1} - 1) - \\mu^\\top K.\n    \\end{align*}\nThen the Karush-Kuhn-Tucker (KKT) Conditions implies that if $K^*$ is a local maximum then there exists a scalar~$\\lambda \\in \\mathbb{R}^1$ and a vector $\\mu \\in \\mathbb{R}^m$ with component $\\mu_j \\geq 0$ such that, for~$i=1,2, \\ldots, m$,\n    \\begin{align}\n        &-\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda - \\mu_i = 0 \\label{eq:partial Ki (risk)} \\\\\n        & K^{*\\top} \\mathbf{1} - 1 = 0 \\label{eq: partical lambda (risk)} \\\\\n        & \\mu_i K_i^* = 0 \\label{eq: Mu_i x Ki* = 0 (risk)}\n    \\end{align}\nFrom Equation~\\eqref{eq:partial Ki (risk)}, we obtain\n    \\begin{align} \\label{eq: Mu_i with lambda (risk)}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] +\\lambda.\n    \\end{align}\nfor $i=1,2, \\ldots, m$. Using the fact that $\\mu_i K_i^* = 0$, for $i=1,2,\\dots,n$, we take weighted sum of Equation~(\\ref{eq: Mu_i with lambda (risk)}) and have\n    \\begin{align*}\n        &\\sum_{i=1}^m \\mu_i K_i^* \\\\\n        &\\quad = \\sum_{i=1}^m K_i^* \\left( -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\right) \\\\\n        &\\quad + \\sum_{i=1}^m K_i^* \\left( \\frac{\\rho}{n} \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n\\rangle \\cdot \\frac{ \\mathcal{R}_{n,i} }{\\langle K^{*}, \\mathcal{R}_n \\rangle}  \\right] + \\lambda \\right) = 0. \n    \\end{align*}\nSince \n$$\n\\sum_{i=1}^m K_i^* \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n= \\mathbb{E}\\left[  \\frac{\\langle K^{*}, \\mathcal{R}_n \\rangle }{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1, \n$$\nand $\\sum_{i=1}^m K_i^* = 1$, we obtain\n    \\begin{align}\n        -1 - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] +\\lambda = 0.\n    \\end{align}\nThus, we have $\\lambda=1$ and substitute it into Equation~(\\ref{eq: Mu_i with lambda (risk)}). This tells us that for $i=1,2, \\ldots, m$,\n    \\begin{align*}\n        \\mu_i \n        &= -\\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\left( 1 + \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\right) \\nonumber \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle }  \\right] + 1.\n    \\end{align*}\n    The fact $\\mu_i K_i^*=0$ implies that if $K_i^* > 0$, then $\\mu_i = 0$ and\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{ \\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \n        - \\frac{\\rho}{n} \\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad + \\frac{\\rho}{n}\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle} \\right] = 1.\n    \\end{align*}\n    If $K_i^* = 0$, then $\\mu_i \\geq 0$, which implies that\n    \\begin{align*}\n        & \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] - \\frac{\\rho}{n}\\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_n \\rangle  \\cdot \\frac{\\mathcal{R}_{n,i}}{\\langle K^{*}, \\mathcal{R}_n \\rangle } \\right] \\\\\n        &\\qquad +\\frac{\\rho}{n}\\mathbb{E}\\left[ \\log(K^{*\\top}\\mathcal{R}_n) \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{n,i}}{K^{*\\top}\\mathcal{R}_n} \\right] \\leq 1.\n    \\end{align*}\nHence, the proof is complete.    \n\\end{proof}\n\n\n\\begin{remark}\\rm\n    While Lemma~\\ref{Lemma: risk term} only provides necessary conditions for optimality, it is possible to construct an example that {\\em extends} these to both necessary and sufficient conditions. For an illustration,  see Section~\\ref{section: Illustrative Examples} to follow.\n\\end{remark}\n\n\n\n\n\\section{Illustrations} \\label{section: Illustrative Examples}\nThis section provides two examples to validate our findings on the impact of the risk-aversion coefficient. The first is on optimal betting and the second is on retail inventory management.\n\n\n\\subsection{Optimal Betting}\n    We now provide an example in optimal betting and illustrate how the risk term~$\\rho$ affects the optimal feedback vector~$K^*$. We consider a two-alternative decision-making process with one risk-less alternative having zero interest rate; i.e., $X_1(k)=0$ with probability one; and the other is a risky alternative with i.i.d. payoffs $X_2(k) \\in \\{ -\\frac{1}{2},\\frac{1}{2} \\}$ with probability\n    $$\n    \\mathbb{P}\\left( X_2(k) = \\frac{1}{2} \\right) := p \\in \\left( \\frac{1}{2}, \\frac{3}{4} \\right).\n    $$\nWith this setting, the log-variance becomes\n\\begin{align*}\n    v(K)\n    & := {\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\\n    & = \\mathbb{E}\\left[ \\left( \\log \\langle K, \\mathcal{R}_n \\rangle  \\right)^2 \\right]  \n        - \\left( \\mathbb{E} \\left[ \\log\\langle K, \\mathcal{R}_n \\rangle  \\right] \\right)^2\\\\\n    & = p (\\log (1 + K_2\/2))^2  + (1-p) \\log (1- K_2\/2 )^2  \\\\\n    & \\qquad - (p \\log (1 + K_2\/2) + (1-p)\\log (1 - K_2\/2)^2.\n\\end{align*}\nA lengthy but straightforward calculation leads to the second-order derivative of $v(K)$:\n\\[\n\\frac{\\partial^2 v(K)}{ \\partial K_2^2 } = \\frac{16 p (1-p)  (2 + K_2 \\log \\frac{2 + K_2 }{2 - K_2} )}{ \\left( K_2^2 - 4 \\right)^2} \\geq 0,\n\\]\nwhich shows that the log-variance $v(K)$ is convex. Therefore, the risk-sensitive objective~\\eqref{eq: risk-sensitive objective} becomes a concave function in~$K_2$, which implies that Problem~\\eqref{problem: risk-sensitive problem} is a concave program. Therefore, Lemma~\\ref{Lemma: risk term} becomes a necessary and sufficient condition for optimality.    \nSpecifically, for~$n=1$, with the aids of Lemma~\\ref{Lemma: risk term}, we have\n\\begin{align*}\n        & \\mathbb{E} \\left[ \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] - \\rho\\mathbb{E}\\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\cdot \\frac{ \\mathcal{R}_{1,2} }{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] \\\\\n        & + \\rho \\mathbb{E} \\left[ \\log \\langle K^{*}, \\mathcal{R}_1 \\rangle \\right] \\mathbb{E}\\left[ \\frac{\\mathcal{R}_{1,2}}{ \\langle K^{*}, \\mathcal{R}_1 \\rangle } \\right] = 1.\n    \\end{align*}\nWe define the left-hand side as a function of $p, K_2$, and $\\rho$, call it $f(p, K_2, \\rho)$. Then, a straightforward calculation leads to\n\\begin{align*}\n    f(p, K_2, \\rho)\n    & =-1 + \\frac{2p}{1+K_2^*}-\\frac{2p\\rho\\log( 1 + K_2^* )}{ 1 + K_2^*}\\\\\n    & + \\frac{2p\\rho\\left( p\\log(1 + K_2^*)+(1-p)\\log(1-K_2^*)\\right)}{1+K_2^*}\\\\\n    & =0.\n\\end{align*}\nNote that, for example, if $\\rho = 0$, the function $f$ has a zero-crossing solution $K_2^* = 2(2p - 1)$, which reduces to the classical Kelly's solution; see~\\cite{Kelly_1956, hsieh2019contributions}.\nAs a second example, if~$p=0.6$, then $K_2^*=0.4$ as $\\rho = 0$. If we increase~$\\rho$ to~$0.1$, we obtain the~$K_2^* \\approx 0.3646$, slightly smaller than~$0.4$, implying that investors will reduce the weight as the risk aversion constant $\\rho$ rises. \nWhen $\\rho$ rises from $0$ to $1$, $K_2^*$ falls by around $0.2$ to $0.2035$; see Figures~\\ref{fig: small p} and \\ref{fig: small p zoom in}.\n\nWe also consider extreme cases such as $p = 0.75$ which yields~$K_2^* = 1$ when $\\rho = 0$ and $K_2^* \\approx 0.5643$ when~$\\rho = 1$; see Figure~\\ref{fig: large p zoom in}. From the cases discussed above, we find that~$K_2^*$ is negatively affected by $\\rho$ and is more sensitive to $\\rho$ as the probability of profiting becomes higher.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1.eps}\n    \\caption{Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ when $p=0.6$.}\n    \\label{fig: small p}\n\\end{figure}\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.6_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p=0.6$.}\n    \\label{fig: small p zoom in}\n\\end{figure}\n\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/p=0.75_n=1_ZoomIn.eps}\n    \\caption{Zoom In: Optimal Feedback Gain $K_2^*$ for $\\rho \\in \\{0, 0.1, 0.2, \\dots, 1\\}$ When $p = 0.75$.}\n    \\label{fig: large p zoom in}\n\\end{figure}\n\n\\begin{remark} \\rm\n    This example illustrates optimal betting and investment decisions and underlines its practical relevance. By illustrating how risk aversion $\\rho$ influences the allocation of resources among different alternatives, we shed light on bridging theoretical models and real-world financial decision-making.  \n\\end{remark}\t\n\n\n\\subsection{Retail Inventory Management}  \n   As a second example, we consider an inventory management problem faced by a retail operation, illustrating the application of a decision-making framework with an uncertain variable demand. \n    Specifically, the retail operation is confronted with the challenge of setting the inventory levels for two distinct categories, encapsulated by feedback gains $K_1$ and~$K_2:=1-K_1$ with~\\(K_i \\in [0, 1]\\). These gains represent the proportion of the maximum possible inventory capacity \\( I_{\\max} \\) units, for an upcoming sales period. These decisions are adjusted in anticipation of demand fluctuations, modeled as~$X_2(k) \\sim {\\rm Uniform}(-1, X_{\\max})$ and $X_1(k) := 0$ with probability one. \n    \n    The retailer's objective is to find the optimal feedback gain vector \\(K\\) that maximizes a risk-sensitive objective function~\\eqref{problem: risk-sensitive problem}, integrating the expected logarithmic profits and the variance of these profits, with the risk aversion parameter~\\( \\rho \\) modulating the influence of risk.\n\nSimilar to the prior example, we first verify the convexity of the log-variance. To this end, define an auxiliary random variable $\\mathcal{X}_{n,i} := \\mathcal{R}_{n,i} -1$ for $i \\in \\{1,2\\}$ and $n\\geq 1$. Note that\n\\begin{align*}\n    v(K)\n    &={\\rm var}\\left( \\log \\frac{V(n; K)}{V_0} \\right) \\\\ \n     &= \\mathbb{E}[(\\log (1+K_2 \\mathcal{X}_{n,2})^2] \n         - \\mathbb{E}[\\log (1+K_2 \\mathcal{X}_{n,2})]^2\\\\\n    & = \\int_{-1}^{(1 + X_{\\max})^n-1} (\\log (1+K_2 x))^2 f_{\\mathcal{X}_{n,2}} (x)dx \\\\\n    &\\qquad - \\left( \\int_{-1}^{(1+X_{\\max})^n-1}  \\log (1+K_2 x)f_{\\mathcal{X}_{n,2}} (x)dx \\right)^2.\n\\end{align*}\nwhere $f_{\\mathcal{X}_{n,2}}$ is the probability density function of induced payoff~$\\mathcal{X}_n$ obtained in Proposition~\\ref{proposition: Erlang compound return} in Appendix.\n\nTo illustrate, we take $I_{\\max} = 1000$ units, symmetric demand volatility $X_{\\max} = 1 = -X_{\\min}$, risk-aversion constant~$\\rho = 1\/2$, and~$n \\geq 1 $,\nFigure~\\ref{fig: Convexity of the Log-Variance} shows the second-order derivative of the log-variance under various $n \\in \\{1, 5, 10\\}$, which is readily seen that $v(K)$ is a convex function; hence, Problem~\\eqref{problem: risk-sensitive problem} is a concave program and Lemma~\\ref{Lemma: risk term} becomes necessary and sufficient conditions. Moreover, by Lemma~\\ref{Lemma: risk term}, with $n=5$, we obtain $K_1^*=1$ and $K_2^*=0$.\n\n\n\\begin{figure}[h!]\n    \\centering\n    \\includegraphics[width=1\\linewidth]{figs\/management_example_logvar_convexity_erlang.eps}\n    \\caption{Convexity of the Log-Variance: $\\frac{\\partial^2 v(K)}{\\partial K_2^2}$ Versus $K_2$.}\n    \\label{fig: Convexity of the Log-Variance}\n\\end{figure}\n\n\n\\begin{remark} \\rm\n    Leveraging a uniform distribution for initial demand fluctuations, which compound into an Erlang-based distribution, underscores the strategic advantage of predictive inventory management in uncertain environments. The optimization of \\(K\\) values based on this compounded demand model supports a {\\em focused} policy, potentially prioritizing a single product category to manage risk and enhance returns effectively. \n\\end{remark}\n    \n \n\n\n\\section{Concluding Remarks} \\label{section: Concluding Remarks}\n    In this paper, we have introduced and examined a new risk-sensitive decision-making model under uncertainty, formulating the problem as a stochastic control problem and establishing necessary optimality conditions.\n    Illustrative examples are given to demonstrate the idea.\n\n    Our findings illuminate the intricate balance between maximizing expected log-growth and mitigating log-variance, providing a robust framework for decision-makers who face uncertain environments. This work has broad implications in financial sectors. Moreover, as seen in Section~\\ref{section: Illustrative Examples}, the model's applicability extends beyond finance, offering valuable perspectives for risk management policies in sectors ranging from optimal betting to inventory management.\n\n    Despite the contributions of this study, we recognize its limitations, including the i.i.d. assumptions on the stochastic alternatives. \n    For future work, one possibility is to explore more generalized models that relax these assumptions, for example, dive into the \\textit{variance-regularized} optimization problem, see~\\cite{duchi2019variance}, and seek possible convex surrogates of log-variance so that it is possible to enhance computational tractability and near-optimality.  \n    Another interesting direction to pursue would be considering other practical constraints in the model such as risk limits~\\cite{jorion2007value} or possible environmental and social constraints~\\cite{eccles2014impact}.\n\n \n \\appendix\n\\label{Induced Return:Uniform_Distribution}\nThis appendix studies the probability density function for induced payoffs\n$\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1 = \\mathcal{R}_n - 1$\nwhere $X(k)$ are i.i.d. uniform distributed random variables on~$[ -1, X_{\\max}]$ with $X_{\\max} > 0$. \n\n\n\\begin{proposition} \\label{proposition: Erlang compound return}\n    The probability density function for a random variable $\\mathcal{X}_n := \\prod_{k=0}^{n-1} (1+X(k)) -1  \\in \\mathbb{R}^1$ is as follows: For $ - 1 < z < \\left( 1 + X_{\\max } \\right)^n - 1$, \n\\[\nf_{{\\cal X}_n } \\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}};\n\\]\t\nOtherwise, $f_{\\mathcal{X}_n}(z)=0.$\n\\end{proposition}\n\n \n\n The proof of the proposition above is established with the aid of the following lemma.\n\n\\begin{lemma} \\label{lemma: auxiliary lemma}\n    Let $X$ be a uniformly distributed random variable on $[-1, X_{\\max}]$ with~$X_{\\max} >0$. Define \n\t$$\n\tY := - \\log \\left( \\frac{1 + X }{1+X_{\\max}} \\right).\n\t$$ \n Then $Y$ is exponentially distributed with parameter $\\lambda=1$; i.e., $Y \\sim \\exp(1)$. \n\\end{lemma}\n \n\n\\begin{proof}\n    We begin with computing the cumulative distribution function (CDF) for $Y$. Note that $F_Y(y) = 0$ for all $y < 0$; therefore, it suffices to consider the CDF for $y \\ge 0 $; namely,\n\\begin{align*}\n\tF_Y(y)\n\t&= \\mathbb{P} \\left(  - \\log \\left( {\\frac{{1 + X}}{1 + X_{\\max } }} \\right) \\le y \\right) \n\t\\\\ \n\t&= \\mathbb{P}\\left( {X \\ge \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {X \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1} \\right).\n\\end{align*}\nNow note that for $y \\ge 0$, \n$$ - 1 \\le \\left( {1 + {X_{\\max }}} \\right){e^{ - y}} - 1 \\le {X_{\\max }}$$ \nand since $X $ is uniform distributed on~$[-1, X_{\\max}]$, we have\n\\begin{align*}\n    F_Y(y)\n    & = 1 - \\frac{{\\left( 1 + X_{\\max} \\right){e^{ - y}} - 1 + 1}}{X_{\\max } + 1}\\\\\n    &= 1 - e^{ - y},\n\\end{align*}\nwhich is the CDF for an exponentially distributed with mean one; i.e., $Y \\sim \\exp(1).$\n\\end{proof}   \n\n\n \\begin{proof}[Proof of Proposition~\\ref{proposition: Erlang compound return}] We begin with computing the cumulative distribution function~$F_{\\mathcal{X}_n}(z)$ for $\\mathcal{X}_n$. Note that~$F_{\\mathcal{X}_n}(z)= 0$ for $z \\le -1$; hence, it suffices to consider the CDF for~$z > -1$;~i.e.,\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t&= \\mathbb{P}\\left( {\\prod\\limits_{k = 0}^{n - 1} {(1 + X(} k)) - 1 \\le z} \\right)\n\t\\\\\n\t&= \\mathbb{P}\\left( {\\sum\\limits_{k = 0}^{n - 1} {\\log (1 + X(k))}  \\le \\log \\left( {1 + z} \\right)} \\right).\n\\end{align*}\nUsing the identity \n{\\small \n\\[\n\\sum_{k = 0}^{n - 1} {\\log (1 + X(k))}  = \\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X( k )}}{1 + X_{\\max }}} \\right)}  + n\\log \\left( {1 + {X_{\\max }}} \\right),\n\\]\n}we have\n{\\small \\begin{align*}\n &\\mathbb{P} ({\\cal X}_n \\le z) \\\\\n\t&= \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} {\\log \\left( {\\frac{{1 + X\\left( k \\right)}}{{1+X_{\\max} }}} \\right)}  + n\\log \\left( {1+X_{\\max} } \\right) \\le \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t&  = \\mathbb{P} \\left( {\\sum_{k = 0}^{n - 1} Y (k) \\ge n\\log \\left( 1 + X_{\\max} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\\end{align*}\n}where\n$ Y(k) := - \\log \\left( \\frac{1 + X( k )}{1+X_{\\max}} \\right)\n$\nfor $k=0,1, \\dots ,n-1$.\nApplying Lemma~\\ref{lemma: auxiliary lemma}, it follows that $Y(k)\\sim \\exp(1)$. Furthermore, since the $Y(k)$ are i.i.d., using the fact that the sum of $n$ i.i.d. random variables with $\\exp(1)$ is~$Erlang(n,1)$, see~\\cite{gubner2006probability}, we have\n$\nE_n := \\sum_{k=0}^{n-1} Y(k) \\sim Erlang(n,1).\n$\nNow noting that $Erlang(n,1)$ has CDF $F_{E_n}(x) =0$ for $x \\le 0$ and\n$\nF_{E_n}(x)= 1 - \\sum_{k=0}^{n-1} \\frac{x^k}{k!}e^{-x}\n$  \nfor $x>0$. Hence, we have\n\\begin{align*}\n\tF_{\\mathcal{X}_n}(z)\n\t& = \\mathbb{P}\\left( { \\sum_{k=0}^{n-1} Y(k)   \\ge n\\log \\left( {1 + {X_{\\max }}} \\right) - \\log \\left( {1 + z} \\right)} \\right)\n\t\\\\\n\t& = \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)  \\ge \\log \\left( {\\frac{{{ {\\left( 1 + X_{\\max } \\right) }^n}}}{{1 + z}}} \\right)} \\right)\n\t\\\\ \n\t&= 1 - \\mathbb{P}\\left( {\\sum_{k=0}^{n-1} Y(k)   \\le \\log  {\\frac{{{{\\left( 1+X_{\\max} \\right)}^n}}}{{1 + z}}} } \\right).\n\\end{align*}\nSince for $-1 < z < (1+X_{\\max})^n -1 $, we have\n\\[\\log \\left( {\\frac{{{{\\left( {1 + {X_{\\max }}} \\right)}^n}}}{{1 + z}}} \\right) > 0.\n\\]\nTherefore, the corresponding CDF for $\\mathcal{X}_n$ is given as follows: For $-1<z < {\\left( {1 + X_{\\max}} \\right)^n} - 1$, we have\n $$\n F_{\\mathcal{X}_n}(z ) =\\frac{{1 + z}}{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}\\sum_{k = 0}^{n - 1} {\\frac{1}{{k!}}{{\\left( {\\log \\left( {\\frac{{{{\\left( {1 + X_{\\max}} \\right)}^n}}}{{1 + z}}} \\right)} \\right)}^k}}\n $$\notherwise, $F_{\\mathcal{X}_n}(z ) = 0.$\nThus, the associated probability density function is obtained by taking the derivative of the CDF above; i.e., For~${ - 1 < z < {{\\left( {1 + {X_{\\max }}} \\right)}^n} - 1}$, we have\n\\[{f_{{\\cal X}_n } }\\left( z \\right) = \\frac{1}{{{{(1 + {X_{\\max }})}^n}\\left( {n - 1} \\right)!}}{\\left( {\\log \\frac{{{{(1 + {X_{\\max }})}^n}}}{{1 + z}}} \\right)^{n - 1}}\\]\t\notherwise, $f_{\\mathcal{X}_n}(z)=0.$  \n\\end{proof}\n \n\n\\bibliographystyle{ieeetr}\n\\bibliography{refs}          \n\n\\end{document}\n","rating_answer":"1. Originality: 8\n2. Method: 9\n3. Credibility: 8\n4. Understandability: 9\n5. Relevance: 8\n6. Quality of Citations: 9\n7. Linguistic style and soundness of grammar: 9\n8. Overall score: 8.5"}
