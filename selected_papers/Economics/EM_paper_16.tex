\begin{document}
\affiliation{$$_affiliation_$$}
\title{On the testability of common trends\\in panel data without placebo periods\thanks{I am grateful to Kaspar W\"uthrich for helpful comments and suggestions.}
\maketitle
	
	\begin{abstract}
		We demonstrate and discuss the testability of the common trend assumption imposed in Difference-in-Differences (DiD) estimation
		in panel data when not relying on multiple pre-treatment periods for running placebo tests. Our testing approach involves two steps: (i) constructing a control group of non-treated units whose pre-treatment outcome distribution matches that of treated units, and (ii) verifying if this matched control group and the original non-treated group share the same time trend in average outcomes. Testing is motivated by the fact that in several (but not all) panel data models, a common trend violation across treatment groups implies and is implied by a common trend violation across pre-treatment outcomes. For this reason, the test verifies a sufficient, but (depending on the model) possibly stronger than necessary condition for DiD-based identification. We investigate the finite sample performance of a testing procedure that is based on double machine learning, which permits controlling for covariates in a data-driven manner, in a simulation study and also apply it to labor market data from the National Supported Work Demonstration.\\[0.5cm]
		{\it JEL Classification:} C12, C21 \\[0.1cm]
		{\it Keywords:} treatment effects, causality, difference-in-differences, hypothesis test, panel data.
	\end{abstract}
	\bigskip
	
	
	
	\thispagestyle{empty}
	\newpage
	\setcounter{page}{1}
	
	
	
	\section{Introduction}
	
	
	The Difference-in-Differences (DiD) approach is a popular method for identifying treatment effects by comparing differences in average outcomes before and after treatment introduction across treated and non-treated groups, as exemplified by seminal applications such as \cite{Snow1855} and \cite{Ashenfelter78}. A crucial assumption for identification in DiD models is the common trend assumption, which imposes that the mean potential outcome without treatment follows the same time trend in both treatment groups, possibly conditional on observed covariates, as discussed in \cite{Abadie2005}, among many others. While the common trend assumption is not directly testable for the before-and-after treatment periods used for effect estimation, placebo tests can be conducted if multiple pre-treatment periods are available.
	
	In this paper, we propose an alternative test for the common trend assumption that does not require multiple pre-treatment periods, but is applicable if the DiD analysis utilizes panel data with the same units observed in pre- and post-treatment periods. The testing approach consist of two steps: (i) constructing a control group of non-treated observations that resembles or matches the treatment group in terms of the distribution of pre-treatment outcomes, and (ii) examining whether this matched control group and the original (i.e. non-matched) non-treated group share the same time trend in terms of their average outcomes under non-treatment. The intuition behind this approach is that in lieu of the treatment group, whose non-treated outcome trend cannot be observed, we utilize the matched control group, which is comparable to the treatment group in terms of pre-treatment outcomes but does not receive the treatment, to check whether its non-treated outcomes follow the same trend as those of the original non-treated group. This testing approach is motivated by the fact that, in several (albeit not all) panel models, a common trend across treatment groups implies and is implied by a common trend across pre-treatment outcomes. This follows in several models from a correlation between the treatment and pre-treatment outcomes under treatment selection bias, which is the reason for applying the DiD approach.
	
	Similar to placebo tests in pre-treatment periods, we note that the suggested method is not a direct test of the common trend assumption, as the potential outcomes of treated units are never observed. However, for a range of models that appear plausible in empirical applications, the average pre- and post-treatment outcomes of the matched control group serve as proxies for the mean potential outcomes that the treatment group would have realized under non-treatment, allowing us to verify the common trend assumption. If the average outcomes across the matched control and total non-treated groups exhibit the same trend, it suggests that differences in the pre-treatment outcome distributions of treated and non-treated groups do not imply differences in the time trends of the mean potential outcome under non-treatment. 
	
	As a caveat, we acknowledge the existence of models, as considered in \cite{ghanem2022selection}, in which the condition we test may be violated despite the satisfaction of common trends across treatment groups required for DiD-based identification. Such a scenario arises, for instance, when there are time-varying unobservables that affect the outcome in the same period but are not correlated over time and are unrelated to the treatment, which is known as strict exogeneity, while time constant unobservables affect the outcomes in either period and the treatment, but satisfy the common trend assumption. In such cases, the pre-treatment outcome becomes correlated with the outcome trend through differences in time-varying unobservables over time, leading to the failure of our testable condition. However, the common trend assumption required for DiD-based identification remains valid, as it does not depend on utilizing pre-treatment outcomes. For this reason, we emphasize that the test verifies a sufficient condition for identification, which is stronger than necessary. However, in scenarios where strict exogeneity, which precludes effects of past outcomes or time-varying unobservables associated with the outcomes on the treatment, seems doubtful, our testing approach provides valuable guidance w.r.t.\ DiD-based identification.
	
	Our testing approach is easily implemented based on existing treatment effect estimators like matching as e.g.\ discussed in \cite{rosenbaum1983} and \cite{RosenbaumRubin1985}, regression, inverse probability weighting (IPW), see \cite{HoTh52}, or doubly robust (DR) estimators, see \cite{Robins+94}, \cite{RoRoZa95}, and \cite{RoRo95}. First, such estimators are utilized to generate a matched control group among non-treated observations whose pre-treatment outcome distribution corresponds to that of the treated group. Second, DiD estimation is applied to the matched control group and the total non-treated group to verify if the time trends in average outcomes are the same for both groups. In this approach, we can easily control for pre-treatment covariates if the common trend assumption is assumed to hold conditionally given those covariates. Moreover, if the set of potential covariates is large, we may control for them in a data-driven manner based on approaches that combine treatment evaluation based on DR estimators with machine learning, such as the double machine learning (DML) framework proposed by \cite{Chetal2018}.
	
	We investigate the finite sample performance of our DML-based testing procedure in a simulation study, which points to decent empirical size and power in the simulation designs considered. We also provide an empirical application to labor market data from the National Supported Work Demonstration (NSW) previously analyzed in \cite{LaLonde86}, \cite{DehejiaWahba99}, and \cite{DeWa02}. The NSW, our treatment of interest, was a labor market program in the 1970s aimed at enhancing the employment prospects of disadvantaged individuals through subsidized employment and job training. In the non-experimental NSW data, in which treated subjects from the experimental NSW study were combined with non-treated individuals from the U.S.\ Panel Study of Income Dynamics, our test rejects the null hypothesis that the matched control and original non-treated groups follow the same average outcome trend when flexibly controlling for several pre-treatment covariates like age, education, ethnicity, and employment status. 	
	
	Our paper is related to placebo tests for DiD based on pre-treatment periods, as for instance discussed in the surveys by \cite{Lechner2010}, and \cite{Rothetal2022}. However, instead of pre-treatment periods, it exploits  the panel structure of the data to construct such tests. Furthermore, our testing approach is closely related to that of  \cite{HuberKueck2022} on testing identification of treatment effects in observational data based on an suspected instrument that is associated with the treatment and is supposedly unrelated with the outcome other than via the treatment. In fact, utilizing the pre-treatment outcome as `instrument' and the outcome difference in post- and pre-treatment periods as outcome variable in the framework of \cite{HuberKueck2022} is the base for the DiD testing approach suggested in this paper. 

	The remainder of this study is organized as follows. Section \ref{Assumptions} discusses assumptions required for identifying the average treatment effect on the treated (ATET) by DiD and testing the common trend assumption by our method. Section \ref{identviol} discusses causal scenarios in which our testable implications as well as DiD-based identification fails, but effects are identified based on a selection-on-observables assumption w.r.t.\ the pre-treatment outcome. Section \ref{timevar} discusses the testable implications and DiD-based identification in the presence of time varying outcome shocks. Section \ref{covariates} considers conditional versions of the common trend assumptions and the testable implications when controlling for observed covariates. Section \ref{testapproach}  proposes machine learning-based tests of common trends that control for covariates in a data-driven manner. 	
	 Section \ref{simulation} provides a simulation study analyzing the finite sample performance of the test. Section \ref{application} presents an application to NSW data. Section \ref{co} concludes.
	
	
	\section{Identifying assumptions and testable implications}\label{Assumptions}
	We consider a panel data DiD setting with $n$ units, $i=1,\dots,n$, that are observed over two periods, $t\in \{0,1\}$.
	Let us denote by $D_i$ a binary treatment variable whose causal effect is of interest. In the pre-treatment period ($t=0$), no unit receives the treatment; in the post-treatment period ($t=1$), a subset of units, referred to as the treatment group, receives the treatment, while the remaining units, referred to as the control group, remain untreated. The observed outcome for unit $i$ in period $t$ is denoted by $Y_{it}$, such that $Y_{i0}$ and $Y_{i1}$ are the observed pre- and post-treatment outcomes, respectively. To define the causal effects of interest, we make use of the potential outcome framework \citep{Neyman23,Rubin74}. We denote by $Y_{it}(d)$ the potential outcome of unit $i$ that would be hypothetically realized under treatment $d\in\{0,1\}$ in period $t$.\footnote{By denoting the potential outcome $Y(d)$ as a function of a subject's own treatment status $D=d$ only, we implicitly impose the assumption that someone's potential outcomes are not affected by the treatment status of others. This is known as the `stable unit treatment value assumption' (SUTVA), see for instance the discussion in \citet{Rubin80} and \citet{Cox58}, and is invoked throughout.} In general, we will use upper case letters to refer to random variables and lower case letters for specific values of these random variables. Moreover, we will suppress the index $i$ to alleviate the notation.
	
Subsequently, we discuss two assumptions necessary for identifying causal effects in DiD settings. The firs one is the common trend assumption, which imposes that the time trend in the mean potential outcomes under non-treatment is constant across treatment groups.
	\begin{assumption}[Common trends]\label{ass1}
		\begin{eqnarray*}
			E[Y_1(0)-Y_0(0)|D=1]=E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)].
		\end{eqnarray*}
	\end{assumption}
\noindent It is this common trend assumption our approach aims to test, even though we cannot verify it directly as the potential outcomes under non-treatment of treated units are never observed. The second assumption (often implicitly) imposed when applying DiD is a no anticipation assumption. 
	\begin{assumption}[No anticipation]\label{ass2}
		$
		Y_0(1)=Y_0(0).$
	\end{assumption}
	\noindent Assumption \ref{ass2} implies that subjects not yet treated in the pre-treatment period do not anticipate their treatment in a way that already influences their pre-treatment outcomes. As our testing approach does not aim at testing this assumption, we will maintain Assumption \ref{ass2} throughout the paper.
	
	Under Assumptions \ref{ass1} and \ref{ass2}, the average treatment effect on the treated (ATET) in period $t=1$, $\Delta_{D=1}$, is identified by the difference in the before-after (treatment introduction) change of average observed outcomes across treatment groups:
	\begin{eqnarray}\label{DiDobs}
		\Delta_{D=1}
		&=&\underbrace{E[Y_1|D=1]-E[Y_0|D=1]}_{\textrm{before-after change among treated}}-\underbrace{\{E[Y_1|D=0]-E[Y_0|D=0]\}}_{\textrm{before-after change among non-treated}}.
	\end{eqnarray}
	
	Next, we will consider a couple of further assumptions, which are required for a fruitful application of out test. The first assumption is that the mean potential outcomes under non-treatment in the pre-treatment period differ across treated and non-treated groups.
	\begin{assumption}[Treatment selection bias]\label{ass3}
		\begin{eqnarray*}
			E[Y_0(0)|D=1]\neq E[Y_0(0)|D=0].
		\end{eqnarray*}
	\end{assumption}
	\noindent Assumption \ref{ass3} implies that selection into treatment is non-random w.r.t.\ pre-treatment outcomes. In fact, allowing for such a treatment selection bias is the main motivation for applying DiD approaches, which permit consistent estimation of the ATET if the difference in mean potential outcomes under non-treatment across treatment groups remains constant or stable over time. The latter  selection bias stability condition is equivalent to the common trend assumption, which can be easily seen by rearranging the first equality in Assumption \ref{ass1} to $E[Y_1(0)|D=1]-E[Y_1(0)|D=0]=E[Y_0(0)|D=1]-E[Y_0(0)|D=0]$. Bias stability is for instance satisfied in a fixed effects model with panel data, in which a time constant unobserved term (like innate ability) is correlated with the treatment (e.g.\ a training program) and has a time constant effect on the outcomes (e.g.\ wage) across pre- and post-treatment periods.  Assumption \ref{ass3} is testable in the data by verifying whether the difference in mean outcomes across treated and non-treated groups in the pre-treatment period is different from zero. To see this, note that
	\begin{eqnarray}\label{diffpretreat}
		E[Y_0|D=1]-E[Y_0|D=1]&=&E[Y_0(1)|D=1]-E[Y_0(0)|D=1]\notag\\
		&=&E[Y_0(0)|D=1]-E[Y_0(0)|D=1],
	\end{eqnarray}
	where the first equality follows from the observational rule, implying that $Y_t=Y_t(1)$ for observations with $D=1$, and the second from the no anticipation assumption.
	
We note that under a violation of Assumption \ref{ass3} and the absence of treatment selection bias in the pre-treatment period, testing the common trend assumption becomes obsolete, as the DiD approach collapses to taking mean outcome differences in the post-treatment period only. To see this, note that
$E[Y_1|D=1]-E[Y_0|D=1]-\{E[Y_1|D=0]-E[Y_0|D=0]\}$ is equal to $E[Y_1|D=1]-E[Y_1|D=1]$ if $E[Y_0|D=1]=E[Y_0|D=0]$. Accordingly, the common trend assumption
$E[Y_1(0)-Y_0(0)|D=1]=E[Y_1(0)-Y_0(0)|D=0]$ simplifies to $E[Y_1(0)|D=1]=E[Y_1(0)|D=0]$ if $E[Y_0(0)|D=1]=E[Y_0(0)|D=0]$, implying that the treatment is assumed to be mean independent of the potential outcomes under non-treatment. For this reason, we will maintain Assumption \ref{ass3} throughout, otherwise the application of a DiD strategy does not appear meaningful.
	
Our next assumption imposes that the common trend assumption also holds for the treated group and a matched control group that resembles the treated group in terms of the distribution of $Y_0(0)$, i.e.\ the potential outcome under non-treatment in the pre-treatment period.
	\begin{assumption}[Common trends across matched groups]\label{ass4}
		\begin{eqnarray*}
			E[E[Y_1(0)-Y_0(0)|Y_0,D=0]|D=1]=E[Y_1(0)-Y_0(0)|D=1].
		\end{eqnarray*}
	\end{assumption}
	\noindent Assumption \ref{ass4} states that the trend of the average outcome in the matched control group is representative for that of the mean potential outcome under non-treatment in the treated group. Consequently, the joint satisfaction of Assumptions \ref{ass1} and \ref{ass4} implies that
	\begin{eqnarray}\label{controlscommon}
		E[E[Y_1(0)-Y_0(0)|Y_0,D=0]|D=1]=E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)].
	\end{eqnarray}
	By the observational rule, this yields the testable implication
	\begin{eqnarray}\label{controlscommontest}
		E[E[Y_1-Y_0|Y_0,D=0]|D=1]=E[Y_1-Y_0|D=0].
	\end{eqnarray}
	\noindent Verifying implication \eqref{controlscommontest} requires that for every value of the pre-treatment outcome among the treated, non-treated observations with the same value of the pre-treatment outcome exist. This is a common support restriction, which means that the conditional treatment probability given any value of the pre-treatment outcome, the so-called propensity score, must be smaller than one, as imposed in our next assumption:
	\begin{assumption}[Common support]\label{commsup}
		\begin{eqnarray*}
			\Pr(D=1|Y_0)<1.
		\end{eqnarray*}
	\end{assumption}

While imposing Assumption \ref{ass4} in addition to Assumption \ref{ass1} appears to be the weakest possible statistical assumption for implementing our testing approach, it is a high level condition whose intuition might not seem straightforward. However, it turns out that in several models, both Assumptions \ref{ass1} and \ref{ass4} are implied by a more easily interpretable assumption imposing common trends across pre-treatment outcomes:
	\begin{assumption}[Common trends across pre-treatment outcomes]\label{ass5}
		\begin{eqnarray*}
			E[Y_1(0)-Y_0(0)|Y_0]=E[Y_1(0)-Y_0(0)].
		\end{eqnarray*}
	\end{assumption}
\noindent The reason for Assumption \ref{ass5} generally implying Assumption \ref{ass1} ais that by Assumption \ref{ass3}, $Y_0$ is correlated with $D$ due to treatment selection bias. This in turn means that if the outcome trend is not correlated with the treatment, as imposed in Assumption  \ref{ass1}, it is not correlated with pre-treatment outcomes either, as imposed in Assumption  \ref{ass5}. Only in very specific models it can be the case that differential trends conditional on $Y_0$, i.e.\  $E[Y_1(0)-Y_0(0)|Y_0=y,D=0]\neq E[Y_1(0)-Y_0(0)|Y_0=y,D=1]$ for some $y$, offset each other in particular ways such that Assumptions  \ref{ass4} and \ref{ass1} as well as implication \eqref{controlscommontest} hold.

Under Assumption \ref{ass1}, the additional satisfaction of Assumption \ref{ass5} generally implies that the treatment and the average outcome trend remain independent even conditional on pre-treatment outcome $Y_0$, apart from such special cases with offsetting associations of the outcome trend and $Y_0$ across values of $D$:
\begin{eqnarray}\label{equalities}
	E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)|Y_0]=E[Y_1(0)-Y_0(0)|Y_0, D=0].
\end{eqnarray}
Therefore, when invoking Assumptions \ref{ass1} and \ref{ass5} rather than Assumptions \ref{ass1} and \ref{ass4}, the testable implication \eqref{controlscommontest} may be simplified by dropping the outer expectation right of the equals sign:
	\begin{eqnarray}\label{controlscommontest2}
		E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0].
	\end{eqnarray}
	This result, which we formalize in Theorem \ref{theorem1} further below, is closely related to Theorem 2 in \cite{HuberKueck2022}. The latter states that if an instrumental variable and an outcome are independent conditional on the treatment, then both the instrument and the treatment are exogenous apart from special cases that violate causal faithfulness, an assumption ruling out offsetting causal effects, as discussed further below. Our pre-treatment outcome $Y_0$ and outcome change $Y_1-Y_0$ correspond to the instrument and the outcome, respectively, in the framework of \cite{HuberKueck2022}. It is worth noting that we only condition on $D=0$ (not $D=1$) when formulating the testable implication, as the common trend assumptions only concern the potential outcomes under non-treatment. In models respecting causal faithfulness, the satisfaction of equation \eqref{controlscommontest2} thus implies that both the pre-treatment outcome and treatment are mean independent of the outcome trend under non-treatment, which is sufficient (albeit stronger than necessary) for the satisfaction of Assumption \ref{ass1} required for identification of the ATET.
	
	To gain further intuition, we subsequently discuss Assumption \ref{ass5} in the context of in parametric and nonparametric models where confounding of the treatment $D$ and the outcome change $Y_1-Y_0$ is due to unobserved fixed effects. 	We start by considering the following parametric outcome and treatment models:
	\begin{eqnarray}\label{linmodel}
		Y_T= \alpha_T + \beta_T D + U,\quad D=I\{\alpha_D+U>0\}
	\end{eqnarray}
	where $U$ is an unobserved fixed (i.e.\ time-constant) effect that affects the pre- and post-treatment outcomes $Y_0, Y_1$ as well as the treatment, thus causing treatment endogeneity or selection bias.  $\beta_T$ is the treatment effect, which is period-dependent and by our linear model homogeneous across individuals. When imposing Assumption \ref{ass2} to rule out anticipation effects as we do in the subsequent discussion, $\beta_0=0$, while $\beta_1$ is non-zero if the treatment has an effect on the outcome. $\alpha_T$ is a period-specific constant term such that a non-zero difference between $\alpha_0$ and $\alpha_1$ implies a non-zero time trend in the outcome. $I\{\cdot\}$ in the treatment model denotes the indicator function, which is equal to 1 if its argument is satisfied and zero otherwise.
	Furthermore, $\alpha_D$ is a constant term. Thus, the treatment is characterized by a simple binary choice model where treatment assignment depends on the size of the fixed effect. 	
	In this model, the potential outcomes under treatment and non-treatment in the post-treatment period correspond to $Y_1(1)=\alpha_1+\beta_1+U$ and $Y_1(0)= \alpha_1+U $, respectively, and $Y_1(1)-Y_1(0)=\beta_1$ gives the homogeneous treatment effect. Concerning the potential outcomes in the pre-treatment period, we have that $Y_0(1)= Y_0(0)= \alpha_0 + U $. Furthermore, the time trend of the potential outcome under non-treatment is homogeneous, i.e.\ for any individual it holds that $Y_1(0)-Y_0(0)=\alpha_1-\alpha_0$. Therefore, the time trend is independent of the pre-treatment outcome $Y_0$ and the treatment state $D$, such that
	Assumption \ref{ass5} and thus, both Assumptions \ref{ass1} and \ref{ass4} are satisfied, as well as the testable implications \eqref{controlscommontest} and \eqref{controlscommontest2}. As $E[Y_1|D=1]-E[Y_0|D=1]=\alpha_1-\alpha_0+\beta_1$, while $E[Y_1|D=0]-E[Y_0|D=0]$ yields the time trend $\alpha_1-\alpha_0$, it holds that the DiD approach, $E[Y_1|D=1]-E[Y_0|D=1]-\{ E[Y_1|D=0]-E[Y_0|D=0]\}$, yields the treatment effect $\beta_1$ as suggested by the testable implications.
	
	It is worth noting that Assumption \ref{ass5} also holds when generalizing the outcome and treatment models in \eqref{linmodel} to some extent. First, we can allow for effect heterogeneity, e.g.\ including an interaction of the treatment with the fixed effect in the outcome model:
	\begin{eqnarray}\label{linmodel2}
		Y_T= \alpha_T + \beta_T D + \gamma_T D U + U,
	\end{eqnarray}
	where $\gamma_T$ is the interaction effect in period $T$. As for $\beta_0$, $\gamma_0$ is necessarily zero under the no anticipation assumption. In this case, the DiD approach correctly identifies the ATET as $\beta_1+\gamma_1 E[U|D=1]$ and $E[Y_1(0)-Y_0(0)|Y_0,D=d]$, while the common trend is again $E[Y_1(0)-Y_0(0)|Y_0,D=d]=\alpha_1-\alpha_0$ such that Assumption \ref{ass5} holds.
	
	Second, we may allow for general functions of $D$ and $U$ in the outcome equation, such as interactions between $D$ and higher order terms of $U$, or for multiple time constant unobservables, such that $U$ is a vector rather than a scalar. This can be formalized by assuming $U$ to be an unknown function $\nu$ of a vector of unobservables $U_1,...U_K$ where $K$ denotes the number the number of unobservables such that $U=\nu(U_1,...U_K)$ and assuming the following model:
	\begin{eqnarray}\label{nonlinmodel3}
		Y_T= \alpha_T + \beta_T(U) D + U,
	\end{eqnarray}
	where the treatment effect $\beta_T(U)$ is now permitted to be heterogeneous in $U$ if $T=1$, while $\beta_0(U)=0$ in the absence of anticipation effects. The ATET corresponds to $E[\beta_T(U)|D=1]$. Alternatively, we may write  \eqref{nonlinmodel3} as
	\begin{eqnarray}\label{nonlinmodel4}
		Y_T= \alpha_T + \phi_T(D,U),
	\end{eqnarray}
	with $\phi_T(D,U)=\beta_T(U) D + U$. This makes explicit that we consider a nonparametric outcome model with an additively separable time trend. Second, the treatment model in \eqref{linmodel} might be replaced by a nonparametric function of both the time constant unobeservable(s) $U$ and further unobservables, denoted by $Q$, if the latter are independent of outcome $Y_T$ conditional on $U$. This implies that conditional on $U$, there are no time-varying unobserved variables jointly affecting $D$ and $Y_T$. Formally,
	\begin{eqnarray}\label{nonlintreat}
		D=\psi(U,Q),
	\end{eqnarray}
	where $\psi$ is an unknown function and $Q$ is independent of $Y_T$ conditional on $U$.
	
	As an alternative to using equations, we can represent our causal framework by causal graphs as e.g.\ considered in \citet{Pearl00}, in which we use directed arrows to present average causal effects between variables, which are represented by edges. Figure \ref{causalchain} provides a causal graph which is in line with outcome model \eqref{nonlinmodel3} and treatment model \eqref{nonlintreat}. In the left graph, the fixed effect $U$ jointly affects the outcomes in either period, while both $U$ and the unobservable $Q$ affect the treatment.  	Furthermore, as implied by Assumption \ref{ass3}, $D$ is associated with $Y_0$, because the unobserved term $U$ which influences the outcomes also affects $D$.
	For this reason, $U$ confounds the causal association of the treatment and the post-treatment outcome, which motivates the DiD approach. 	The right graph provides the causal framework when replacing $Y_1$ by the difference in post- and pre-treatment outcomes $Y_1-Y_0$. Importantly, the time constant unobservable term $U$ does not affect $Y_1-Y_0$, as it cancels out due to the additive separability $\alpha_T$  and $U$ in model \eqref{nonlinmodel3}, implying that $U$ does not interact with the time trend. Therefore, the average causal association of $D$ and $Y_1-Y_0$ is unconfounded and DiD identifies the ATET.
	
	
	\tikzstyle{EdgeStyle}   = [->,>=stealth']
	\begin{figure}[!htp]
		\centering \caption{\label{causalchain}  Causal framework satisfying Assumption \ref{ass5}}\bigskip
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1}   \SO(D){U}  \NO(D){Q} 			\Edges(D,Y1) \Edges(U,Y0) \Edges(U,D)  \Edges(U,Y1) \Edges(Q,D) 		\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1-Y0} \NO(D){Q}   \SO(D){U}  			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D) \Edges(Q,D)  		\end{tikzpicture}
	\end{figure}
	
	
	In the previously considered models, the period-specific constant $\alpha_T$ was additively separable and thus, independent of $U$ and $D$. If this is not the case, Assumption \ref{ass5} generally fails, as well as Assumptions \ref{ass1} and \ref{ass4}. Consider for instance a specification where the period-specific constant depends on the fixed effect, e.g.\ though an interaction of $\alpha_T$ and $U$:
	\begin{eqnarray}\label{nonsepmodel}
		Y_T= \alpha_T U + \beta_T(U) D +  U.
	\end{eqnarray}
	The time trend is now given by $E[Y_1(0)-Y_0(0)|D=d]=(\alpha_1-\alpha_0)\cdot E[U|D=d]$. In our setup where $U$ assumably affects $D$, this implies differential trends across treatment groups such that Assumption \ref{ass1} is violated and DiD does not identify the ATET. Furthermore, $E[Y_1(0)-Y_0(0)|Y_0=y, D=d]=(\alpha_1-\alpha_0)\cdot E[U|Y_0=y, D=d]$ for $d$ $\in$ $\{1,0\}$ generally differs across pre-treatment outcome values $y$, because $Y_0=(1+\alpha_0)U$ is a function $U$. Therefore, Assumptions \ref{ass1} and \ref{ass4} are generally violated, as well as the testable implication \eqref{controlscommontest2}.
	
	Figure \ref{causalchain2} presents causal graphs for scenarios which generally violate the common trend assumptions. In the upper graphs, $U$ affects $Y_0$ and $Y_1$ as well as $Y_1-Y_0$, in line with model \ref{nonsepmodel} where the period-specific constant $\alpha_T$ depends on the fixed effect. For this reason, $U$ confounds the causal relation between $D$ and $Y_1-Y_0$ by jointly affecting $D$ and $Y_1-Y_0$. In the lower graphs, a time-varying unobservable $Q$ affects both $D$ and $Y_1$. For instance, sector-specific recessions ($Q$) might induce retraining activities ($D$) among certain employees while also affecting wages in future periods ($Y_1$). In this case, the outcome difference $Y_1-Y_0$ does not difference out $Q$, which was not present in the pre-treatment period 0 yet (or took a different value). For this reason $Q$ confounds the causal relation between $D$ and $Y_1-Y_0$, implying a differential time trend for treated and non-treated groups and a violation of Assumption \ref{ass5}.
	
	In both the scenarios in the upper and lower graphs, it is easy to see that the testable implication \eqref{controlscommontest2} is violated as $Y_0$ is associated with $Y_1-Y_0$ conditional on $D=0$. In the upper graphs, the correlation is due to $U$ directly affecting both $Y_0$ and $Y_1-Y_0$. In the lower graphs, conditioning on $D=0$ introduces so-called collider bias, i.e.\ a spurious association between $U$ and $Q$ via $D$, see e.g.\ \citet{Pearl00}. Collider bias comes from the fact that both $U$ and $Q$ affect $D$ such that conditioning on $D=0$ causes  $U$ and $Q$ to be associated, which is also known as sample selection bias in economics, see e.g.\ \citet{He76}. Through this conditional association of $U$ and $Q$, $Y_0$ and $Y_1-Y_0$ are conditionally associated, too, as $U$ affects $Y_0$ and $Q$ affects $Y_1-Y_0$. 
	
	In our model, a violation of Assumption \ref{ass5} and implication \eqref{controlscommontest2} generally also implies the violation of Assumptions \ref{ass1} and \ref{ass4} and the testable implication \eqref{controlscommontest}, apart from special cases. Only under quite specific effect heterogeneities captured by $\beta(U)$ in model \eqref{nonsepmodel}, it may happen that differential trends conditional on $Y_0$, i.e.\  $E[Y_1(0)-Y_0(0)|Y_0=y,D=0]\neq E[Y_1(0)-Y_0(0)|Y_0=y,D=1]$ for some $y$, average out in particular ways such that Assumptions  \ref{ass4} and \ref{ass1} as well as implication \eqref{controlscommontest} hold. Yet, one might prefer testing this latter condition (rather than the maybe more intuitive condition \eqref{controlscommontest2} related to the stronger Assumption \ref{ass5}), because it is based on the weakest possible model assumptions for testing identification based on DiD. For binary outcomes, for instance, Assumption \ref{ass5} is only satisfied if the common trend is equal to zero such that any non-treated outcome is constant over time, which may seem implausible. In contrast, Assumption \ref{ass4} can hold in admittedly quite specific models with non-zero trends in which Assumption \ref{ass5} is violated.
	
	\tikzstyle{EdgeStyle}   = [->,>=stealth']
	\begin{figure}[!htp]
		\centering \caption{\label{causalchain2}  Causal frameworks not satisfying Assumption \ref{ass5}}\bigskip
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1}   \SO(D){U}  \NO(D){Q} 			\Edges(D,Y1) \Edges(U,Y0) \Edges(U,D)  \Edges(U,Y1) \Edges(Q,D) 		\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}  \NO(D){Q} 			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D)  \Edges(U, Y1-Y0) \Edges(Q,D) 		\end{tikzpicture}\vspace{10 pt}\\
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1}   \SO(D){U}   \NO(D){Q} 			\Edges(D,Y1) \Edges(U,Y0) \Edges(U,D)  \Edges(U,Y1) \Edges(Q,D)  \Edges(Q,Y1) 		\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}   \NO(D){Q} 			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D)      \Edges(Q,D)  \Edges(Q,Y1-Y0)   		\end{tikzpicture}
	\end{figure}
	
	Theorem \ref{theorem1} demonstrates that implication \eqref{controlscommontest2} is satisfied if and only if both Assumptions \ref{ass1} and \ref{ass5} among non-treated observations hold, conditional on Assumption \ref{ass3} and the causal faithfulness (or stability) assumption, which rules out special cases of models in which causal mechanisms between variables cancel each other out exactly, see for instance \citet{spirtes2000causation} and \citet{Pearl00}. As an example, consider the upper graphs of Figure \ref{causalchain2} and assume that the confounding effects due to $U$ directly affecting $Y_0$ and the collider bias introduced by conditioning on $D=0$ exactly offset each other. In this case, the implication \eqref{controlscommontest2} would hold despite a violation of Assumption \ref{ass1}. For this reason, we invoke causal stability, which excludes such special cases of offsetting mechanisms. The proof of Theorem \ref{theorem1} is provided in Appendix \ref{proofth1}.
	\begin{theorem}\label{theorem1}
		\begin{eqnarray*}
			&&E[Y_1(0)-Y_0(0)| Y_0]=E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)]\\ &\iff&  E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0].\notag
		\end{eqnarray*}
		Conditional on 		causal faithfulness (no offsetting mechanisms) and Assumption \ref{ass3}, the testable implication \eqref{controlscommontest2} is necessary and sufficient for the joint satisfaction of Assumptions \ref{ass1} and \ref{ass5}.
	\end{theorem}
	
	By Theorem \ref{theorem1}, the satisfaction of the testable implication \eqref{controlscommontest2} is sufficient for DiD-based identification, as both Assumptions \ref{ass1} and \ref{ass5} hold. However, it is important to note that there also exist further panel models in which DiD-based identification is feasible even under a violation of implication \eqref{controlscommontest2} such that the latter is not a necessary condition, as discussed further below. Furthermore, we point out that our test generally cannot detect violations of the common trend assumption if they exclusively concern the potential outcomes under non-treatment of treated subjects, but not of non-treated subjects. Such a situation would arise if there existed distinct potential outcome models for treated and non-treated observations and period-fixed effect-interactions like $\alpha_T  U$ in equation \eqref{nonsepmodel}  exclusively occurred among treated, but not among non-treated observations. However, this may not appear very realistic in many empirical applications, because we would suspect a certain overlap in the (unobserved) background characteristics of treated and non-treated groups. This in turn should make it likely that if such period-fixed effect-interactions exist, they should occur in both treatment groups, such that our test should be able to detect such violations of the common trend assumption among the non-treated.
	
	
	\section{Identification based on selection-on-observables}\label{identviol}
	
	In this section, we explore a case where identification remains feasible despite violations of our testable implications, utilizing a different method than DiD, which entails distinct models and assumptions from those discussed previously. Let us consider a modification of the treatment model provided in equation \eqref{nonlintreat}, assuming that (i) the pre-treatment outcome $Y_0$ affects treatment $D$, and (ii) $U$ influences $D$ solely through $Y_0$, but not directly. Additional, we assume that the common trend assumption fails such that the time trend interacts with $U$, as in equation \eqref{nonsepmodel}. This scenario implies the satisfaction of a so-called selection-on-observables assumption, while the conventional common trend assumption stipulated in Assumption \ref{ass1} is violated.
	
	\tikzstyle{EdgeStyle}   = [->,>=stealth']
	\begin{figure}[!htp]
		\centering \caption{\label{causalchain3}  Causal framework satisfying selection on observables}\bigskip
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1}   \SO(D){U} \NO(D){Q}  			\Edges(Y0,D,Y1) \Edges(U,Y0)   \Edges(U,Y1) \Edges(Q,D)		\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0}  \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U} \NO(D){Q}  			\Edges(Y0,D,Y1-Y0) \Edges(U,Y0)   \Edges(U,Y1-Y0) \Edges(Q,D)
		\end{tikzpicture}
	\end{figure}
	
	The causal graph in Figure \ref{causalchain3} illustrates such a scenario. Interestingly,  even though Assumption \ref{ass1} does not hold, Assumptions \ref{ass5} and \ref{ass4} are satisfied, because $E[U|Y_0=y, D=1]=E[U|Y_0=y, D=0]$.  The latter implies that common trends across treatment states hold conditional on pre-treatment outcomes:
	\begin{eqnarray}\label{homocommon}
		E[Y_1(0)-Y_0(0)|Y_0,D=1]=E[Y_1(0)-Y_0(0)|Y_0,D=0].
	\end{eqnarray}
	By the law of iterated expectations, equation \eqref{homocommon} is a sufficient condition for Assumption \ref{ass4}. However, whether or not Assumption \ref{ass4} holds, Assumption \ref{ass1} is violated such that equation \eqref{controlscommon} and the testable implications  \eqref{controlscommontest} are violated, correctly suggesting that the DiD approach is inconsistent. This is due to $U$ jointly affecting $D$ and $Y_1-Y_0$, because $U$ is not additively separable from the time trend.
	
	Nevertheless, it is worth pointing out that the satisfaction of equation \eqref{homocommon} implies that the treatment is mean independent of potential outcomes in the post-treatment period conditional on the pre-treatment outcome, such that treatment selection is based on an observable, namely $Y_0$. To see this, note that for some value $Y(0)=y$, equation \eqref{homocommon} can be rewritten as
	\begin{eqnarray}\label{homocommon2}
		&&E[Y_1(0)-Y_0(0)|Y_0=y,D=1]=E[Y_1(0)-Y_0(0)|Y_0=y,D=0],\notag\\
		&=& E[Y_1(0)-Y_0(0)|Y_0(0)=y,D=1]=E[Y_1(0)-Y_0(0)|Y_0(0)=y,D=0],\notag\\
		&=& E[Y_1(0)|Y_0(0)=y,D=1]-y=E[Y_1(0)|Y_0(0)=y,D=0]-y,\notag\\
		&\Leftrightarrow& E[Y_1(0)|Y_0(0)=y,D=1]=E[Y_1(0)|Y_0(0)=y,D=0],
	\end{eqnarray}
	where the second line follows from $Y_0=Y_0(0)$ under Assumption \ref{ass2}. For this reason, controlling for pre-treatment outcomes permits identifying average treatment effects, e.g.\ based on matching treated and non-treated observations with comparable pre-treatment outcomes, see \citet{Im04} for a review on estimation approaches in this context. 	However, our testing framework is tailored to testing common trends, and for this reason, it cannot be used to verify the satisfaction of the selection-on-observables assumption, implying that the treatment is as good as random after controlling for $Y_0$, which underlies this matching approach.  The violation of \eqref{controlscommontest} points to a violation of Assumption \ref{ass1}, no matter whether \eqref{homocommon2} holds. On the other hand, the satisfaction of  \eqref{controlscommontest} implies the satisfaction of common trend assumption, but the selection-on-observables assumption may either hold or fail, namely if $U$ affects $D$ directly (contrarily to Figure \ref{causalchain3}), rather than exclusively through $Y_0$.
	
	\section{Models with time-varying outcome shocks}\label{timevar}
	
	
	The models examined thus far have not incorporated time-varying outcome shocks, i.e., time-varying unobservable factors or error terms affecting the outcomes in the same period. It is important to note that introducing such error terms, which is plausible in many causal scenarios, may lead to models where Assumption \ref{ass1}, the common trend assumption required for DiD-based identification, holds, while Assumptions \ref{ass5} and \ref{ass4}, as well as the testable implications \eqref{controlscommontest} and \eqref{controlscommontest2}, are violated. In such instances, our testing approach may incorrectly reject identification based on DiD asymptotically.
	To illustrate this, let us, for instance, reconsider the parametric models in expression \eqref{linmodel} (albeit nonparametric models could be extended analogously) and add a time-varying error term to the outcome equation, denoted by $V_T$, which is (conditionally) mean zero, i.e., $E[V_T|D,U]=E[V_T]=0$. The linear outcome model now becomes
  \begin{eqnarray}\label{linmodelranderr}
		Y_T= \alpha_T + \beta_T D + U + V_T,
	\end{eqnarray}
	while we maintain the treatment model provided in \eqref{linmodel}. 
	
	Equation \eqref{linmodelranderr} corresponds to conventional linear panel regression models as considered in classical fixed effects regression, see for instance \citet{Wooldridge02book}. The condition that time-varying unobservables $V_T$ are uncorrelated with $D$ given $U$, as implied by $E[V_T|D,U]=0$, is known as strict exogeneity in such models. $V_T$ can be interpreted as conditionally random outcome shock that does not entail confounding of the treatment $D$ and the outcome change $Y_1-Y_0$. In particular, $E[Y_1(0)-Y_0(0)|D=d]=\alpha_1-\alpha_0+E[V_1-V_0|D=d]=\alpha_1-\alpha_0$, because $E[V_T | D]=0$ as $V_T$ neither influences nor is influenced by $D$ according to our model, such that Assumption \ref{ass1} holds. Furthermore, we have that $E[Y_1(0)-Y_0(0)|Y_0]=\alpha_1-\alpha_0+E[V_1-V_0|Y_0]$. However, $E[V_1-V_0|Y_0]$ is in general not zero, because the conditioning variable $Y_0$ is a function of the pre-treatment error $V_0$, which is generally correlated with the difference $V_1-V_0$.\footnote{For instance, assume the simplistic case that $V_1$ is a constant. In this case, $V_1-V_0$ is perfectly negatively correlated with $V_0$.} Therefore, Assumptions \ref{ass5} and \ref{ass4} as well the testable implications \eqref{controlscommontest} and \eqref{controlscommontest2} are generally violated. Summing up,  Assumption \ref{ass1}, the common trend assumption which is necessary for DiD-based identification, holds, while the sufficient (but not necessary) testable implications are violated.
	
	The left graph in Figure \ref{causalchainviol} illustrates this scenario. Via the correlation of $V_0$ and $V_1-V_0$, $Y_0$ is correlated with $Y_1-Y_0$, which is an example for a so-called back-door path between $Y_0$ and  $Y_1-Y_0$ in the denomination of \citet{Pearl00}. For this reason, Assumption \ref{ass5} fails, while Assumption \ref{ass1} holds, because $U$ affects $D$, but not $Y_1-Y_0$. See also the discussion in \ref{xu2023causal}, which highlights that strict exogeneity is sufficient for the common trend assumption required for ATET identification. 
	
	\tikzstyle{EdgeStyle}   = [->,>=stealth']
	\begin{figure}[!htp]
		\centering \caption{\label{causalchainviol}  Causal framework satisfying Assumption \ref{ass1} and violating (left) or satisfying (right) Assumption \ref{ass5}}\bigskip
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0} \NO(Y0){V0} \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}  \NO(Y1-Y0){V1-V0}
			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D)   \Edges(V0,Y0) \Edges(V1-V0,Y1-Y0) \Edges(V0,V1-V0)\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0} \NO(Y0){V0} \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}  \NO(Y1-Y0){V1-V0}
			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D)   \Edges(V0,Y0) \Edges(V1-V0,Y1-Y0)
		\end{tikzpicture}
	\end{figure}
	
	It is worth mentioning that there exists a special case in which $V_0$ and $V1-V0$ are not correlated, namely if $V_1$ follows a so-called random walk, such that it is strongly serially correlated with $V_0$:
	\begin{eqnarray}\label{ranwalk}
		V_1=V_0+W_1 \Leftrightarrow V_1-V_0=W_1,
	\end{eqnarray}
	where $W_1$ is an independent unobservable (or random shock) in period 1, $E[W_1|V_0]=E[W_1]=0$, implying that $E[V_1|V_0]=V_0$. Under a random walk, $V_1-V_0=W_1$ is not correlated with error $V_0$, such that there is no correlation of $Y_0$ and $Y_1-Y_0$. This is illustrated in the right graph of Figure \ref{causalchainviol}. However, we emphasize that apart from a random walk, the presence of time-varying unobservables in the outcome equation implies a violation of our testable implications, even if Assumption \ref{ass1} holds.
	
	
	In this context with time-varying unobserved variables $V_T$, it is interesting to look at the implications of our test under a modification of our model that permits for a non-zero impact of the pre-treatment outcome $Y_0$ on treatment $D$, as previously considered in Figure \ref{causalchain3}. Consequently, we modify the causal models in Figure \ref{causalchainviol} by also adding a direct effect of $Y_0$ on $D$, as provided in Figure \ref{causalchainviol2} and also considered in \cite{ChabeFerret2017}. This constitutes a violation of strict exogeneity, with its implications more thoroughly discussed in \cite{imai2019should}, as $V_0$ affects $D$ via $Y_0$. In this causal model, testing Assumption \ref{ass5} is well aligned with verifying the satisfaction of Assumption \ref{ass1}. In the left graph, Assumption \ref{ass5} is violated for the very same reasons as discussed for the left graph of Figure \ref{causalchainviol}. However, also Assumption \ref{ass1} is violated, as $V_0$ jointly affects the outcome change $Y_1-Y_0$ via $V_1-V_0$ and the treatment $D$ via $Y_0$. This back-door path between the treatment and the outcome change implies a failure of the common trend assumption across treatment groups such that DiD does not identify the ATET, as also discussed in \cite{ghanem2022selection}. Such a back-door path does, however, not exist in the case that $V_1-V_0$ is not correlated $V_1$, i.e.\ under a random walk, as provided in the right graph of Figure \ref{causalchainviol2}, where the pre-treatment error $V_0$ is not associated with the outcome change $Y_1-Y_0$. For this reason, both Assumptions \ref{ass1} and \ref{ass5} are satisfied. In summary, in scenarios where strict exogeneity, which precludes effects of past outcomes or past time-varying unobservables associated with the outcomes on the treatment, appears doubtful or implausible, our test provides valuable guidance for DiD-based identification.
	
		\tikzstyle{EdgeStyle}   = [->,>=stealth']
	\begin{figure}[!htp]
		\centering \caption{\label{causalchainviol2}  Causal framework violating (left) or satisfying (right) Assumptions \ref{ass1} and \ref{ass5}}\bigskip
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0} \NO(Y0){V0} \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}  \NO(Y1-Y0){V1-V0}
			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D)  \Edges(Y0,D)  \Edges(V0,Y0) \Edges(V1-V0,Y1-Y0) \Edges(V0,V1-V0)\end{tikzpicture}\qquad
		\begin{tikzpicture}[scale=1]
			\SetGraphUnit{2}
			\Vertex{Y0} \NO(Y0){V0} \EA(Y0){D}  \EA(D){Y1-Y0}   \SO(D){U}  \NO(Y1-Y0){V1-V0}
			\Edges(D,Y1-Y0) \Edges(U,Y0) \Edges(U,D) \Edges(Y0,D)  \Edges(V0,Y0) \Edges(V1-V0,Y1-Y0)
		\end{tikzpicture}
	\end{figure}
	

	\section{Common trends conditional on covariates}\label{covariates}
		
	In many applications, common trends might only appear plausible when comparing treated and non-treated observations that are similar in terms of observed covariates, henceforth denoted by $X$, as for instance discussed in \citet{Abadie2005}. When e.g.\ assessing the effect of a minimum wage on earnings, the common trend assumption may only seem realistic for the earnings of treated and non-treated individuals that are employed in the same industry, as earnings trends may differ across industries. This implies that the common trend assumption does not hold unconditionally across regions introducing and not introducing a minimum wage, if the region differ in terms of industry structure. However, by controlling for covariates through adjusting their distribution in the non-treated group to match that of the treated group, the common trend assumption \ref{ass1} is assumed to hold conditional on $X$, as formalized in Assumption \ref{ass1a}:
	\begin{assumption}[Common trends across treatment groups conditional on covariates]\label{ass1a}
		\begin{eqnarray*}
			E[Y_1(0)-Y_0(0)|X, D=1]=E[Y_1(0)-Y_0(0)|X, D=0]=E[Y_1(0)-Y_0(0)| X].
		\end{eqnarray*}
	\end{assumption}
	
	Furthermore, let us assume that also Assumptions \ref{ass2}, \ref{ass3}, \ref{commsup} hold conditional on covariates, as postulated in Assumptions \ref{ass2a} to \ref{commsupa}.
	\begin{assumption}[No anticipation conditional on covariates]\label{ass2a}
		\begin{eqnarray*}
			\Pr(Y_0(1)=Y_0(0)|X)=0.
		\end{eqnarray*}
	\end{assumption}
	\begin{assumption}[Treatment selection bias conditional on covariates]\label{ass3a}
		\begin{eqnarray*}
			E[Y_0(0)|D=1]\neq E[Y_0(0)|D=0].
		\end{eqnarray*}
	\end{assumption}
	\begin{assumption}[Common support conditional on covariates]\label{commsupa}
		\begin{eqnarray*}
			\Pr(D=1|X,Y_0)<1.
		\end{eqnarray*}
	\end{assumption}
	Under Assumptions \ref{ass1a}, \ref{ass2a}, and \ref{commsupa} (or the slightly weaker common support restriction $\Pr(D=1|X)<1$), the ATET is identified in analogy to \eqref{DiDobscovar} by
	\begin{eqnarray}\label{DiDobscovar}
		\Delta_{D=1}&=&E[Y_1(1)|D=1]-E[Y_1(0)|D=1]\notag\\
		&=&E[Y_1(1)|D=1]-E[Y_0(0)|D=1]-E[E[Y_1(0)|X,D=1]+E[Y_0(0)|X,D=1]|D=1]\notag\\
		&=&E[Y_1|D=1]-E[Y_0|D=1]-\{E[E[Y_1|X,D=0]-E[Y_0|X,D=0]|D=1]\},
	\end{eqnarray}
	where the second quality follows from the law of iterated expectations.
	
	Furthermore, when controlling for $X$, Assumption \ref{ass4} becomes
	\begin{assumption}[Common trends across matched groups conditional on covariates]\label{ass4a}
		\begin{eqnarray*}
			E[E[Y_1(0)-Y_0(0)|Y_0,X,D=0]|X,D=1]=E[Y_1(0)-Y_0(0)|X,D=1].
		\end{eqnarray*}
	\end{assumption}
	In analogy to equation \eqref{controlscommontest}, the satisfaction of both Assumptions \ref{ass1a} and \ref{ass4a} implies the testable implication
	\begin{eqnarray}\label{controlscommontesta}
		E[E[Y_1-Y_0|Y_0,X,D=0]|X,D=1]=E[Y_1-Y_0|X,D=0],
	\end{eqnarray}
	given that the common support assumption \ref{commsupa} holds. By averaging the conditional means in equation \eqref{controlscommontesta} over the distribution of $X$ in the treated group, which is required for the identification of the ATET in \eqref{DiDobscovar}, we obtain a further testable implication:
	\begin{eqnarray}\label{controlscommontestb}
		E[E[Y_1-Y_0|Y_0,X,D=0]|D=1]=E[E[Y_1-Y_0|X,D=0]|D=1],
	\end{eqnarray}
	which follows from $E[E[E[Y_1-Y_0|Y_0,X,D=0]|X,D=1]|D=1]=E[E[Y_1-Y_0|Y_0,X,D=0]|D=1]$ by the law of iterated expectations.
	
	Conditional on $X$, Assumption \ref{ass5} changes to
	\begin{assumption}[Common trends across pre-treatment outcomes conditional on covariates]\label{ass5a}
		\begin{eqnarray*}
			E[Y_1(0)-Y_0(0)|Y_0,X]=E[Y_1(0)-Y_0(0)|X].
		\end{eqnarray*}
	\end{assumption}
	Under Assumptions \ref{ass1a} and \ref{ass5a}, it holds in analogy to implication \eqref{controlscommontest2} that
	\begin{eqnarray}\label{controlscommontest2a}
		E[Y_1-Y_0|Y_0,X,D=0]=E[Y_1-Y_0|X,D=0].
	\end{eqnarray}
	Finally, averaging the conditional means in equation \eqref{controlscommontest2a} over the distribution of $X$ conditional on $D=1$ yields once again the previously mentioned testable implication \eqref{controlscommontestb}.
	
	
	\section{Testing}\label{testapproach}
	
	This section suggests a machine learning-based method for testing implication \eqref{controlscommontestb} to jointly verify the conditional common trend assumptions \ref{ass1a} and \ref{ass4a}, but also briefly sketches possible approaches for testing implication \eqref{controlscommontest2a}
	when replacing Assumption \ref{ass4a} by the stronger Assumption \ref{ass5a}. Furthermore, it briefly discusses methods for testing implication \eqref{controlscommontest} to jointly verify common trend assumptions \ref{ass1} and \ref{ass4}, which do not involve covariates $X$, as well as implication \eqref{controlscommontest2}	when replacing Assumption \ref{ass4} by the stronger Assumption \ref{ass5}. Starting with the latter scenario, let us denote the conditional mean difference in outcomes given $Y_0$ and $D=0$ as $\mu(y_0)=E[Y_1-Y_0|Y_0=y_0,D=0]$. Implication \eqref{controlscommontest2} is equivalent to the following null hypothesis $H_0$:
	\begin{eqnarray}\label{nullhyp1}
		H_0: \mu(y_0)-\mu(y_0')=0\quad\forall y_0\neq y_0'\textrm{ in the support of }Y_0,
	\end{eqnarray}
	If the outcome $Y_t$ is binary, equation \eqref{nullhyp1} can be easily tested by an OLS regression of $Y_1-Y_0$ on the binary $Y_0$ and a constant in the sample of non-treated observations and an inspection of the p-value of the coefficient on $Y_0$. If the outcome $Y_t$ is non-binary but discrete, one may regress $Y_1-Y_0$ on a constant and indicator variables for the discrete values of $Y_0$, with only one value not being modeled by an indicator to avoid perfect multicollinearity. Running an F-test for the joint coefficients of the indicator variables yields a test of the null hypothesis \eqref{nullhyp1}. If the outcome is continuously distributed, the null hypothesis may e.g.\ be tested by running a univariate nonparametric regression of $Y_1-Y_0$ on $Y_0$ in the sample of non-treated observations and test whether the first derivatives w.r.t.\ $Y_0$ are zero for all observations, see for instance the kernel regression-based statistical significance test suggested by \cite{racine1997consistent}.
	
	When assuming that common trends hold conditional on covariates $X$ as postulated in Assumptions \ref{ass1a} and \ref{ass5a}, the null hypothesis to be tested becomes
	\begin{eqnarray}\label{nullhyp1a}
		H_0: \mu(y_0,x)-\mu(y_0',x)=0\quad\forall y_0\neq y_0'\textrm{ in the support of }Y_0\textrm{ and }x\textrm{ in the support of }X,
	\end{eqnarray}
	with $\mu(y_0,x)=E[Y_1-Y_0|Y_0=y_0, X=x, D=0]$ denoting the conditional mean difference in outcomes given $Y_0$, $X$, and $D=0$. This null hypothesis may e.g.\ be verified by tests that investigate whether the mean squared error increases significantly when dropping $Y_0$ from the outcome regression model  $\mu(Y_0,X)$, see e.g.\ the approaches suggested in \citet{HuberKueck2022} and \citet{kook2024algorithmagnostic}. 
	
	Next, let us consider testing implication \eqref{controlscommontest} for jointly verifying Assumptions \ref{ass1} and \ref{ass4}. In this case, the null hypothesis is given by
	\begin{eqnarray} \label{H0_ass1ass4}
		H_0: E[\mu(Y_0)|D=1]-E[Y_1-Y_0|D=0]=0,
	\end{eqnarray}
	We may estimate the two conditional means in equation \eqref{H0_ass1ass4} by their sample analogs conditional of $D=1$ and $D=0$, respectively, and $\mu(Y_0)$ by regression (as discussed before)  in order to construct a test for a violation of the null, typically based on the t-statistic. 
	
	Finally, when assuming that such common trend assumptions only hold conditional on $X$, we consider the testable implication \eqref{controlscommontestb} for jointly verifying  Assumptions \ref{ass1a} and \ref{ass4a} based on the following null hypothesis:
	\begin{eqnarray} \label{H0_ass1ass4X}
		H_0: E[\mu(Y_0,X) |D=1]-E[\mu(X)|D=1]=0,
	\end{eqnarray}
	with $\mu(y_0, x)=E[Y_1-Y_0|Y_0=y_0, X=x,D=0]$ and $\mu(x)=E[Y_1-Y_0|X=x,D=0]$. Using insights from doubly robust (DR) statistics as for instance considered in \citet{Robins+94} and \citet{RoRo95}, it follows that \eqref{H0_ass1ass4X} is equivalent to
	\begin{eqnarray} \label{H0_ass1ass4DR}
		H_0: \theta&=&0,\textrm{ where}\notag\\		
		\theta&=&E\left[\frac{\mu(Y_0,X)\cdot D}{\Pr(D=1)}+\frac{(Y_1-Y_0-\mu(Y_0,X))\cdot (1-D)\cdot p(Y_0,X)}{(1-p(Y_0,X)\cdot \Pr(D=1))} \right]\notag\\
		&-&E\left[ \frac{\mu(X)\cdot D}{\Pr(D=1)}+\frac{(Y_1-Y_0-\mu(X))\cdot (1-D)\cdot p(X)}{(1-p(X)\cdot \Pr(D=1))}\right],
	\end{eqnarray}
	with $p(X)=\Pr(D=1|X)$ and $p(Y_0,X)=\Pr(D=1|Y_0,X)$ denoting the conditional treatment probabilities, also known as propensity scores.\footnote{To see the equivalence of the expressions in \eqref{H0_ass1ass4X} and \eqref{H0_ass1ass4DR}, consider the first expectation in either expression. Note that by basic probability theory $E\left[\frac{\mu(Y_0,X)\cdot D}{\Pr(D=1)}\right]=E[\mu(Y_0,X) |D=1]$, while by the law of iterated expectations $E\left[ \frac{(Y-\mu(Y_0,X))\cdot (1-D)\cdot p(Y_0,X)}{(1-p(Y_0,X)\cdot \Pr(D=1))} \right]=0$ because $E[Y-\mu(Y_0,X)|Y_0,X,D=0]=0$. An analogous result can be shown for the equivalence of the second expectation in expressions \eqref{H0_ass1ass4} and \eqref{H0_ass1ass4X}, respectively.}
	We may estimate the expectations in expression \eqref{H0_ass1ass4DR} by their respective sample analogs and the plug-in (or nuisance) parameters $\mu(Y_0,X)$, $p(Y_0,X)$, $\mu(X)$, and $p(X)$ by machine learning (ML) algorithms, in order to control for important confounders in a data-driven way,  	which appears particularly attractive if $X$ is high-dimensional. This approach is known as double machine learning (DML); see \citet{Chetal2018} for a seminal discussion, as well as \citet{Chang2020} and \cite{Zimmert2018} for DiD-based DML estimators.
	
	DML is conventionally combined with so-called cross-fitting, which consists of estimating the model parameters of the plug-in parameters (like regression coefficients) and the mean difference $\theta$ in expression \eqref{H0_ass1ass4DR} in non-overlapping subsets of the data, with the roles of the subsets for the estimation steps being sequentially swapped. As no observation enters both estimation steps at the same time, cross-fitting avoids correlations between the estimation of the model parameters of $\mu(Y_0,X)$, $p(Y_0,X)$, $\mu(X)$, and $p(X)$ on the one hand and of the mean difference $\theta$  on the other hand and thus, overfitting bias. Averaging over the mean differences obtained from the various subsets of the data yields the final estimate for testing the null hypothesis in expression \eqref{H0_ass1ass4DR}. Under specific regularity conditions discussed in \cite{Chetal2018}, in particular if the ML-based estimators of the plug-in parameters converge to the respective true models with a rate of at least $n^{1/4}$, DML estimation of the mean differences in expression \eqref{H0_ass1ass4DR} is root-$n$-consistent and asymptotically normal. Furthermore, the results in \cite{Chetal2018} imply that asymptotic variance of the estimator of $\theta$ corresponds to $\sigma^2/n$ where $n$ is the sample size and $\sigma^2$ is the variance of the difference of the terms in the expectations of expression \eqref{H0_ass1ass4DR}:
	\begin{align} \label{varscore}
		\sigma^2=Var& \left(\frac{\mu(Y_0,X)\cdot D}{\Pr(D=1)}+\frac{(Y_1-Y_0-\mu(Y_0,X))\cdot (1-D)\cdot p(Y_0,X)}{(1-p(Y_0,X)\cdot \Pr(D=1))}\right.\\
		&\left.-\frac{\mu(X)\cdot D}{\Pr(D=1)}-\frac{(Y_1-Y_0-\mu(X))\cdot (1-D)\cdot p(X)}{(1-p(X)\cdot \Pr(D=1))}\right).\notag
	\end{align} 
 Also the variance $\sigma^2$ can be consistently estimated under specific regularity conditions. 
	
	\section{Simulation study}\label{simulation}
	
	This section provides a simulation study to investigate the finite sample behavior of our testing approach based on the following data generating process:
	\begin{eqnarray*}
		Y_0 &=& U + \beta_{V_0}V_0,\quad D = I\{X'\beta_{X} + U  + Q >0\},\\
		Y_1 &=& 1 + D + X'\beta_{X}  + (1+\beta_U) U - \beta_Q Q+V_1, \\
		X &\sim& N(0,\sigma^2_X), V_0\sim N(0,1),  V_1\sim N(0,1), U\sim N(0,1),  Q\sim N(0,1), \\ 
		&&\textrm{ with }X,V_0,V_1,U,Q\textrm{ being independent of each other}.
	\end{eqnarray*}
	The pre-treatment outcome $Y_0$ is a function of the fixed effect $U$ and the period-specific unobservable $V_0$ if the coefficient $\beta_{V_0} \neq 0$, while the time-varying constant $\alpha_0$ is equal to zero. The binary treatment $D$ is a function of the fixed effect $U$, a further unobservable $Q$, and covariates $X$ for coefficient vector $\beta_X \neq 0$. The post-treatment outcome $Y_1$ is a linear function of the time-varying  constant $\alpha_1=1$, treatment $D$, whose effect equals 1, covariates $X$ for $\beta_X \neq 0$, and the time-varying unobservable $V_1$. $Y_1$ is also a function of unobservable $Q$ if the coefficient $\beta_Q \neq 0$, as well as of the fixed effect $U$. We note that for $\beta_U\neq 0$, the outcome trends are heterogeneous in $U$ such that the common trend assumption is violated, because $U$ is not netted out when subtracting $Y_0$ from $Y_1$ (even conditional on $D$ and $X$).
	
	The covariate vector $X$ has a multivariate normal distribution with a zero mean and a covariance matrix $\sigma^2_X$ that is obtained by setting the covariance of the $i$th and $j$th covariate in $X$  to $0.5^{|i-j|}$. Furthermore, $U$ and $Q$ are standard normally distributed and independent of each other, as well as of $X$. $\beta_X$ gauges the effects of the covariates on $Y_1$ and $Y_1-Y_0$ alike (because $X$ does not affect $Y_0$) as well as on $D$, respectively, and thus, the magnitude of confounding due to observables. The $i$th element in the coefficient vector $\beta_X$ is set to $0.7/i$ for $i=1,...,p$, with $p$ denoting the number of covariates. This implies a linear decay of covariate importance in terms of confounding of $D$ and the average trend of the potential outcomes under non-treatment, $Y_1(0)-Y_0(0)$.
	
	We consider testing whether the estimate of the DR-based mean difference $\theta$ in expression \eqref{H0_ass1ass4DR} is statistically different from zero, which may point to a violation of the common trends assumption. We estimate this mean difference based on DML as discussed in Section \ref{testapproach}, using two subsets (or folds) of the data for cross-fitting. We estimate the model specifications of the plug-in parameters by lasso regression (linear regression for estimating $\mu(Y_0,X)$ and $\mu(X)$ and logit regression for estimating $p(Y_0,X)$ and $p(X)$) with cross-validated penalty terms, see \citet{Tibshirani96}. Observations with propensity score estimates of $p(Y_0,X)$ or $p(X)$ that are very close to one, namely larger than $0.99$ (or 99\	
	In our first simulation study, we set $\beta_U=0$ (no trend heterogeneity in the fixed effect), $\beta_Q=0$ (no confounding due to $Q$), and $\beta_{V_0}=0$ (implying that $V_1-V_0=V_1$, which is uncorrelated with $Y_0$). In this setting, all conditional common trend assumptions given $X$ are satisfied, namely Assumptions \ref{ass1a}, \ref{ass4a}, and \ref{ass5a}. The upper panel of Table \ref{tab:sim} provides the results. In line with the satisfaction of common trends, the average estimate of the DR-based difference $\theta$ in expression \eqref{H0_ass1ass4DR} (`mean est') is close to zero for either samples size across the $1000$ simulations. Furthermore, the estimator seems to converge at $\sqrt{n}$-rate, as the standard deviation (`std') is roughly reduced by half when quadrupling the sample size from 1000 to 4000. We also see that at least for the larger sample size, the average standard error of the estimator (`mean se') is similar to the actual standard deviation. The average p-value (`mean pval') of rejecting the null hypothesis of of $\theta=0$ based on a t-test amounts to 42 and 47\	
	In a next step, we set $\beta_U=0.5$ while maintaining $\beta_Q=\beta_{V_0}=0$, such that the trend in the mean potential outcomes is heterogeneous in the fixed effect $U$ and Assumptions \ref{ass1a}, \ref{ass4a}, and \ref{ass5a} are violated. The second upper panel of Table \ref{tab:sim} provides the results for this scenario. The average estimate of $\theta$ now amounts to roughly 0.49 under the smaller and 0.55 under the larger sample size, respectively. Furthermore, the average p-values are close to zero and the rejection rates are 99\	
	\begin{table}[htbp]
		\begin{center}
			\caption{Simulations satisfying or violating common trends}
			\label{tab:sim}
			\begin{tabular}{c|ccccccc}
				\hline\hline
				sample size  & mean est & std & mean se & mean pval & rejection & bias & rmse \\
				\hline
				&\multicolumn{6}{c}{$\beta_{V_0}=0$, $\beta_U=0$, $\beta_Q=0$: Assumptions \ref{ass1a}, \ref{ass4a}, and \ref{ass5a} hold} \\
				1000 & -0.03 & 0.10 & 0.08 & 0.42 & 0.10 & 0.14 & 0.18 \\   
				4000 &  -0.01 & 0.06 & 0.05 & 0.47 & 0.06 & 0.04 & 0.06 \\ 
				\hline
				&\multicolumn{6}{c}{$\beta_{V_0}=0$, $\beta_U=0.5$, $\beta_Q=0$: Assumptions \ref{ass1a}, \ref{ass4a}, and \ref{ass5a} violated} \\
				1000  & 0.49 & 0.12 & 0.09 & 0.00 & 0.99 & 0.73 & 0.73 \\ 
				4000 & 0.55 & 0.06 & 0.05 & 0.00 & 1.00 & 0.61 & 0.62 \\ 
				\hline
				&\multicolumn{6}{c}{$\beta_{V_0}=0$, $\beta_U=0$, $\beta_Q=0.5$: Assumptions \ref{ass1a}, \ref{ass4a}, and \ref{ass5a} violated} \\
				1000 & 0.17 & 0.11 & 0.10 & 0.18 & 0.39 & -0.45 & 0.46 \\ 
			    4000 & 0.26 & 0.06 & 0.06 & 0.00 & 0.99 & -0.57 & 0.57 \\ 
				\hline
				&\multicolumn{6}{c}{$\beta_{V_0}=0.5$, $\beta_U=0$, $\beta_Q=0$: Assumption \ref{ass1a} holds, Assumptions \ref{ass4a} and \ref{ass5a} violated} \\
				1000   & -0.30 & 0.10 & 0.08 & 0.03 & 0.92 & 0.16 & 0.20 \\ 
				4000 & -0.32 & 0.05 & 0.05 & 0.00 & 1.00 & 0.06 & 0.08 \\
				\hline
			\end{tabular}
		\end{center}
		\par
		{\scriptsize Notes: columns `mean est', `std', and  `mean se' provide the average estimate of $\Delta$, its standard deviation, and the average of the estimated standard error across simulations, respectively. `rejection pval' and `rejection rate' give the average p-value of the test and the empirical rejection rate when setting the level of statistical significance to 0.05 (or 5\	\end{table}
	
Finally, we examine a data generating process where Assumption \ref{ass1a}, sufficient for DiD-based identification conditional on $X$, is met, but Assumptions \ref{ass4a} and \ref{ass5a} are violated. To this end, we set $\beta_{V_0}=0.5$ and $\beta_U=\beta_Q=0$, resulting in $V_0$ affecting $Y_0$, and the difference $V_1-V_0$ being correlated with $V_0$ and thus with $Y_0$. This mirrors the scenario depicted in the left graph of Figure \ref{causalchainviol} when keeping $X$ fixed. As shown in the bottom panel of Table \ref{tab:sim}, the rejection rates of the test are 92\ 
\section{Empirical application}\label{application}
		
This section presents an empirical application using labor market data from \cite{LaLonde86} concerning the National Supported Work Demonstration (NSW), a U.S.\ federally funded program in the 1970s aimed at enhancing the employment prospects of disadvantaged individuals through subsidized employment and job training. The dataset comprises both an experimental sample, where the program was randomly assigned, and observational data, where treated subjects from the experiment are combined with non-treated subjects from the Panel Study of Income Dynamics (PSID). Researchers such as \cite{LaLonde86}, \cite{DehejiaWahba99}, and \cite{DeWa02} analyzed these data to explore how closely non-experimental estimators, based on the selection-on-observables assumption, approximate the effect estimate in the experimental data. Additionally, \cite{SmithTodd00} consider DiD-based approaches and generally found them to be closer to the experimental estimate compared to competing methods (such as matching) based on the selection-on-observables assumption.\footnote{However, we point out that one should interpret these findings cautiously, as the experimental estimate itself is subject to non-negligible uncertainty or variance due to the limited experimental sample size.}

Here, we test whether the estimate of the DR-based mean difference \(\theta\) in expression \eqref{H0_ass1ass4DR} is statistically different from zero in the PSID sample analyzed in \cite{DehejiaWahba99}, which represent a subsample of the NSW data of \cite{LaLonde86}  and is available in the \textit{causalsense} package by \cite{causalsens} for \textsf{R}.
The pre-and post-treatment outcomes \(Y_0, Y_1\) are real earnings in US dollars in 1975 and 1978, respectively, while the treatment \(D\) is a binary indicator for program assignment. The covariates \(X\) include age, years of education as well as binary indicators for not possessing a high school diploma, ethnicity, marital status, and being unemployed in the pre-treatment year 1975. To increase model flexibility, we also include interaction terms between each pair of covariates and squared terms for the non-binary covariates age and education, entailing all in all 32 variables in \(X\). As for the simulations discussed in Section \ref{simulation}, estimation is based on DML with 2-fold cross-fitting and lasso regression for the estimation of the plug-in parameters, where we drop (or trim) observations with propensity score estimates of \(p(Y_0,X)\) or \(p(X)\) that are larger than 0.99 (or 99\
Table \ref{tab:app} reports the results for the PSID sample, namely the estimate of the test statistic \(\theta\) (`test stat'), its standard error (`se'), and p-value (`pval'). Additionally, we report the DiD-based ATET estimate from DML with 2-fold cross-fitting, lasso regression, and trimming (`ATET') along with its standard error and p-value. The test statistic amounts to 990.56 US dollars with a standard error of 310.58.  Consequently, the p-value is close to zero, implying the rejection of the null hypothesis of common trends as postulated in equation \eqref{H0_ass1ass4DR} at any conventional level of statistical significance. The DiD-based ATET estimate is 2430.84 dollars, which is somewhat larger than the experimental estimate of 1794.30 (with a heteroscedasticity-robust standard error of 672.68) that is based on the treated and non-treated observations in the experimental sample. 



   	
		\begin{table}[htbp]
		\begin{center}
			\caption{Empirical application}
			\label{tab:app}
			\begin{tabular}{ccc|ccc}
				\hline\hline
				 test stat & se & pval & ATET & se & pval  \\
				 990.56 & 310.58 &  0.00 &  2430.84 & 1448.34 &  0.01 \\ 
				 \hline
			\end{tabular}
		\end{center}
		\par
		{\scriptsize Notes: columns `test stat', `se', and `pval' are the estimate of $\theta$ in expression \eqref{H0_ass1ass4DR}, its standard error, and its p-value, respectively. Columns  `ATET', `se', and `pval' are the DiD-based estimate of the ATET, its standard error, and its p-value, respectively.}
	\end{table}

	\section{Conclusion}\label{co}
	
We suggested a placebo test for the DiD-related common trend assumption in panel data  with the same units in both the pre- and post-treatment periods that does not rely on multiple pre-treatment periods. The testing approach is based on constructing a control group of non-treated observations that resembles the treatment group in terms of the distribution of pre-treatment outcomes and verifying whether this matched control group and the total (i.e. non-matched) non-treated group share the same time trend in terms of their average outcomes (under non-treatment). If the matched control and total non-treated groups share the same average outcome trend, this suggests that differences in the pre-treatment outcome distributions of treated and non-treated groups do not imply differences in the time trends of the mean potential outcome under non-treatment. However, we point out that there exist specific models in which the implication that we test is violated, even though the common trend assumption required for DiD-based identification is satisfied. With this regard, our test verifies a sufficient condition for identification, which is, however, stronger than necessary.  
We also investigated the finite sample performance of our DML-based testing procedure in a simulation study and found it to perform very satisfactorily in the simulation designs considered. Finally, we provided an empirical illustration utilizing labor market data from the National Supported Work Demonstration.
	
	\newpage
	{\large \renewcommand{\theequation}{A-\arabic{equation}} 		\setcounter{equation}{0} \appendix
	}
	\appendix \numberwithin{equation}{section}
	{\small
		\section{Appendix}
		
		\subsection{Proof of Theorem \ref{theorem1}}\label{proofth1}
		
		We subsequently provide a proof for Theorem \ref{theorem1}. 		The latter states that conditional on causal faithfulness and Assumption \ref{ass3},  $E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0]$ is a necessary and sufficient condition for $E[Y_1(0)-Y_0(0)| Y_0]=E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)]$ such that both Assumptions \ref{ass1} and \ref{ass5} hold.
		
		We show this result based on a proof by contradiction. To this end, let us assume that in addition to causal faithfulness and Assumption \ref{ass3},  also Assumptions \ref{ass1} and \ref{ass5} hold, while $E[Y_1(0)-Y_0(0)| Y_0, D=0]\neq E[Y_1(0)-Y_0(0)|D=0]$. The latter inequality necessarily implies that $D$ is a collider between $Y_0$ and the time trend $Y_1(0)-Y_0(0)$ in the sense of \citet{Pearl00}, meaning that controlling for $D$ introduces a non-zero correlation between $Y_0$ and $Y_1(0)-Y_0(0)$. To see this, first note that by Assumptions \ref{ass1} and \ref{ass5}, $Y_0$ is mean independent of $Y_1(0)-Y_0(0)$, while by Assumption \ref{ass3}, $Y_0$ is correlated with $D$. Under causal faithfulness, the correlation of $Y_0$ and $D$ may only come from a non-zero average causal effect of $Y_0$ on $D$ and/or from unobserved variables affecting both $Y_0$ and $D$. If conditioning on $D$ introduces a correlation between $Y_0$ and $Y_1(0)-Y_0(0)$, then there must necessarily exist a confounder affecting both $D$ and $Y_1(0)-Y_0(0)$. This follows from a combination of the so-called d-separation criterion of \citet{pearl1988probabilistic},\footnote{Formally, the d-separation criterion implies that two (sets of) variables $A$ and $B$ are d-separated when conditioning on a (set of) control variable(s) $C$ if and only if (i) the path between $A$ and $B$ contains a triple $A\rightarrow M \rightarrow B$ (causal chain) or $A\leftarrow M \rightarrow B$ (confounding) such that variable (set) $M$ is in $C$ (i.e.\ controlled for), (ii) the path between $A$ and $B$ contains a collider $A\rightarrow  S  \leftarrow B$ such that variable (set) $S$ or any variable (set) causally affected by $S$ is not in $C$ (i.e.\ not controlled for).} which implies that $D$ is a collider if either a confounder affects both $D$ and $Y_1(0)-Y_0(0)$ or $Y_1(0)-Y_0(0)$ has a non-zero average effect on $D$. However, the latter possibility is infeasible, because the outcome $Y_1$ is measured in the post-treatment period and can thus not affect the (earlier) treatment $D$, such that (reverse) causality from $Y_1$ to $D$ is ruled out. The remaining possibility of confounders affecting both $D$ and $Y_1(0)-Y_0(0)$ violates (and thus, contradicts) Assumption \ref{ass1}. This in turn implies that if Assumption \ref{ass1} holds such that $D$ is not a collider and controlling on $D$ does not introduce a correlation between $Y_1(0)-Y_0(0)$ and $Y_0$, then $E[Y_1-Y_0|Y_0,D=0]\neq E[Y_1-Y_0|D=0]$ must be due to a correlation of $Y_0$ and $Y_1(0)-Y_0(0)$. The latter, however, violates (and thus, contradicts) Assumption \ref{ass5}.
		
		We have demonstrated that the joint satisfaction of causal faithfulness as well as Assumptions \ref{ass1}, \ref{ass3}, and \ref{ass5} necessarily implies $E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0]$. Next, we also show the converse, namely that conditional on causal faithfulness and Assumption \ref{ass3}, $E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0]$ necessarily implies the joint satisfaction of Assumptions \ref{ass1} and \ref{ass5}. In our proof by contradiction, we assume that $E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0]$ holds while Assumptions \ref{ass1} and/or \ref{ass5} are violated. The latter violations imply confounders of $D$ and $Y_1(0)-Y_0(0)$ and/or a correlation of $Y_0$ and $Y_1(0)-Y_0(0)$. For the reasons discussed before, any of these violations imply $E[Y_1-Y_0|Y_0,D=0]\neq E[Y_1-Y_0|D=0]$ and thus create a contradiction. Therefore, it follows that
		\begin{eqnarray}\label{nesandsuf2}
			&&E[Y_1(0)-Y_0(0)| Y_0]=E[Y_1(0)-Y_0(0)|D=0]=E[Y_1(0)-Y_0(0)]\\ &\iff&  E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0],\notag
		\end{eqnarray}
		such that $E[Y_1-Y_0|Y_0,D=0]=E[Y_1-Y_0|D=0]$ is necessary and sufficient for Assumption \ref{ass1} and \ref{ass5}, conditional on causal faithfulness and Assumption \ref{ass3}.
		
		
		\newpage
		\setlength\baselineskip{14.0pt}
		\bibliographystyle{econometrica}
		\bibliography{research}
	\end{document}
	
	
