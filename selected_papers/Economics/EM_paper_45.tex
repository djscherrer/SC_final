\begin{document}
\affiliation{$$_affiliation_$$}
\title{\textsf{\textbf{Evaluating the Quality of Answers in Political Q\&A Sessions with Large Language Models}
\maketitle

\begin{abstract}
    This paper presents a new approach to evaluating the quality of answers in political question-and-answer sessions. We propose to measure an answer’s quality based on the degree to which it allows us to infer the initial question accurately. This conception of answer quality inherently reflects their relevance to initial questions. Drawing parallels with semantic search, we argue that this measurement approach can be operationalized by fine-tuning a large language model on the observed corpus of questions and answers without additional labeled data. We showcase our measurement approach within the context of the Question Period in the Canadian House of Commons. Our approach yields valuable insights into the correlates of the quality of answers in the Question Period. We find that answer quality varies significantly based on the party affiliation of the members of Parliament asking the questions and uncover a meaningful correlation between answer quality and the topics of the questions.
\end{abstract}

\bigskip

\noindent \textsf{\textbf{Keywords:}} answer quality; Canadian politics; large language models; natural language processing; political Q\&A sessions; Question Period; semantic search

\clearpage

\lettrine[lines=3]{B}{ull} (\citeyear[p.~115]{bull_1994}) contends that ``in any democratic system, questions play an important role in political communication.'' This assertion is supported by the high prevalence of the question-and-answer format in political debates and discussions, wherein politicians field questions from citizens, journalists, and political opponents. Notable examples include congressional hearings, election debates, press conferences, and town hall meetings. Exchanges of questions and answers are also held in formal institutions, such as parliamentary assemblies, in which it is common practice for members to be periodically allowed to question government ministers. Among other things, this practice enables legislature members to fulfill their role as formal overseers of the executive branch.

Given that the overt objective of question-and-answer (Q\&A) sessions is to elicit pertinent answers, although it is not necessarily the only one pursued by the actors involved, it is only natural to seek to evaluate the quality of replies. The latter has important implications for the efficacy of the political institutions, formal and informal, espousing the question-and-answer format.

Although evaluating the quality of replies in political Q\&A sessions may seem natural, it presents significant challenges. At the forefront of these challenges lies the task of defining answer quality, which proves daunting due to the intricate and multifaceted nature of the concept. As an illustration, \citet{bull_mayer_1993} identified 30 different ways of not replying to a question in political interviews. Furthermore, manually annotating large datasets containing thousands or even millions of interactions is prohibitively costly, time-consuming, and prone to errors.

Given these challenges, we propose a novel criterion for evaluating the quality of answers in political Q\&A sessions. We suggest assessing an answer's quality based on the extent to which its text allows us to identify or infer accurately the initial question. This conception of answer quality reflects their relevance to initial questions. A key advantage of our proposed approach is that it can be computationally operationalized by fine-tuning a language model on the observed corpus of questions and answers without additional labeled data. This stems from the close similarity between our conception of answer quality and semantic search, a core task in information retrieval and natural language processing \citep{INR-032}. Briefly, semantic search consists of interpreting the meaning of a query and identifying the value in a database most relevant to it. Therefore, we can employ state-of-the-art semantic search techniques to operationalize our criterion.

We articulate and showcase our methodology in the context of the Question Period in the Canadian House of Commons. The House of Commons is the Parliament of Canada’s lower chamber, where the Prime Minister and other federal Cabinet ministers sit. The Question Period is a significant moment in Canadian parliamentary life. It takes place for 45 minutes each day the House meets and garners close attention from the media and public. This exercise allows members of Parliament, particularly those from opposition parties, to seek information from the government. It is one of the rare moments in Parliament during which the opposition, rather than the government, determines the topics discussed. In this article, we extensively discuss how our conception of the quality of answers aligns with the formal and informal functions fulfilled by the Question Period.

We analyze the exchanges that transpired during the Question Period over more than 15 years, from 2006 to 2021. This amounts to 58,343 exchanges, each comprising a question and an answer. After estimating the quality of answers, we investigate their correlates. In doing so, we demonstrate our approach’s reliability and value. Substantively, our focus is directed at two questions. First, we investigate the relationship between answer quality and the balance of power in the House of Commons. Second, we consider whether answer quality differs based on the topic of the initial question.

We find that answer quality is correlated with the party affiliation of the member who asks the question, with questions from members of third parties (as opposed to the official opposition) and those of parties closer ideologically to the governing party receiving, on average, more pertinent answers. Regarding the government’s willingness to answer questions based on their topic, we find notable similarities between the Conservative and Liberal parties, although differences still exist. For instance, questions about allegedly broken promises, budget deficits, corruption allegations, expense scandals, foreign investments, government advertising, jobs and unemployment, lobbying activities, natural security, political fundraising, supposed conflicts of interest, and taxes tend to receive, on average, less relevant answers. In contrast, questions about issues over which parties are perceived to have a better reputation tend to receive more germane answers.

This paper is organized as follows. As a preamble, we discuss how our research relates to and contributes to the academic literature. Next, we describe the origins and functions of the Question Period. In light of this description, we formally define our conception of answer quality. We explain the data and methodology used to operationalize this conception. After explaining our approach to evaluating the quality of answers in the Question Period, we formulate conjectures about their relationship with relevant variables, which we empirically examine. We conclude by discussing the applicability of our measurement approach to other contexts, both within and beyond the realm of political science.

\section*{Related Literature}

This paper is strongly connected to two bodies of academic literature, one substantive and one methodological.

From a substantive point of view, this paper contributes to the literature studying parliamentary proceedings, specifically parliamentary questions. This literature is founded on the premise that parliamentary questions are a central mechanism through which legislatures enforce government accountability \citep{martin_2011}. Parliamentary questions are the primary conduit through which the executive and legislative branches of government interact directly on a daily basis. Furthermore, question times typically garner more attention from the media and public than any other parliamentary activity. Thus, parliamentary questions represent a preeminent topic of interest for scholarly research in political science.

Among recent work on parliamentary questions, our paper is most closely related to research investigating how well ministers reply to questions and the extent to which they employ avoidance strategies in doing so \citep{RASIAH2010664, bull_strawson_2019, kukec_2022}. These efforts are intricately connected to a larger body of literature on evasion in political communication, particularly in political interviews \citep{bull_mayer_1993, bull_1994, bull_1998, bull_2000, bull_2004, Waddle_Bull_2020}. Unlike previous studies, which typically relied on human annotation, ours employs novel computational tools to address these research questions. Also, our paper expands the previously cited work to the Canadian context.\footnote{No work has previously considered explicitly the quality of answers during the Question Period in the Canadian House of Commons. Although \citet{alvarez_morrier_2024} do not directly contemplate the relevance of answers relative to questions, they study the responsiveness of parties, including the ruling party, to the public salience of climate change in the Question Period. Among other things, they reveal that the attention paid by the government to climate change is significantly correlated with the attention opposition parties pay to that issue, suggesting that the government’s answers are somehow relevant to the opposition’s questions.}

Relatedly, \citet{maricut-akbik_2021} put forward a framework for evaluating the effectiveness of parliamentary questions based on principal-agent theory, the public administration literature on accountability, and communication research. This framework posits that the efficacy of parliamentary questions hinges critically on the relevance of the answers. Thus, it implies that questions must be analyzed in relation to their answers and vice-versa. By introducing a computational approach to achieve this, our work closely aligns with \citeauthor{maricut-akbik_2021}’s framework and boosts its relevance to empirical research.

From a methodological standpoint, this paper belongs to the literature importing tools from computational text analysis into political science. Specifically, this paper is the first to leverage semantic search to answer substantive questions in political science. Our semantic search model is built on sentence embeddings derived from a variant of Bidirectional Encoder Representations from Transformers (BERT) called ``Sentence-BERT’’ \citep{reimers2019sentencebert}. BERT and its numerous variants have not been fully embraced in political science, with only a few studies incorporating their use \citep{hu-etal-2022-conflibert, Wankmuller_2022, Bestvater_Monroe_2023, Uveges_Ring_2023, Wang_2023, Widmann_Wich_2023, Laurer_van_Atteveldt_Casas_Welbers_2024}. Embeddings from Sentence-BERT are distinct from the token or word embeddings, like word2vec and GloVe. Word embeddings have already proven valuable in answering central questions in political science. However, standard word embeddings only offer context-independent language representations, meaning that they do not reflect the meaning of a token within the specific context in which it is used. Given the omnipresence of polysemy and complex semantics, context-independent representations present severe limitations. This justifies the development of word representations that account for the context in which words are employed. Accordingly, embeddings from Sentence-BERT reflect the meaning of individual tokens in the context in which they were used and, based on it, yield a representation of the overall connotation of a sentence. These embeddings have demonstrated a superior performance for semantic search than alternatives.

Finally, this paper contributes to the literature on conversational analysis in natural language processing. We introduce a novel approach for evaluating the relevance of statements in a conversation relative to the preceding statements. This is particularly, although not exclusively, relevant to debates and discussions embracing a question-and-answer format. As we discuss in the conclusion, the potential applications of this approach extend well beyond political science.

\section*{The Foundations and Functions of the Question Period}

The Question Period occurs every day the House of Commons sits \citep[chap.~11]{HOC_PNP}. It is the most visible part of daily parliamentary proceedings. This 45-minute segment is fast-paced, with each question and answer being limited to 35 seconds. It usually begins with the Speaker of the House granting the Leader of the Opposition or their deputy the opportunity to ask questions, often directed at the Prime Minister. Subsequent questions are posed according to a predetermined rotation based on the parties’ representation in the House. While backbench members of the ruling party and independent members of Parliament are also periodically granted the opportunity to ask questions, they are less likely to be called on than members of officially recognized opposition parties. The party caucuses and their whips are responsible for managing the participation of their members in the Question Period. They determine which members will participate and provide the Speaker’s office with a suggested recognition order. The government has the discretion to choose which of its members will reply to a question. According to the Cabinet’s collective responsibility, any minister may answer a question directed at one of them. Parliamentary secretaries can also answer questions on behalf of the government.

The Question Period serves dual purposes as an accountability and monitoring mechanism and a public relations exercise. Formally, the purpose of the Question Period is to allow members of Parliament to seek information from the government and call it to account for its conduct and decisions. Its origin stems from the principle of responsible government, a constitutional convention stipulating that the government is accountable to the House of Commons and, as such, must command the confidence of a majority of its members to remain in office. Concretely, this means that some motions on which the House is periodically called to vote must be adopted; else, the government must either resign or seek the dissolution of Parliament. These so-called ``motions of confidence’’ include the budget, motions introduced by opposition parties declaring that the House has lost confidence in the government, or motions, including legislation, proclaimed by the government to engage the House’s confidence in the government. Responsible government also manifests through regular opportunities enshrined into parliamentary proceedings for members of Parliament to scrutinize the government's decisions, seek redress for perceived missteps, and, if dissatisfied, let it be known that they have lost confidence in the government. The Question Period is one, and arguably the most prominent, of these mechanisms.

The Parliament's role as the government’s formal overseer is especially noticeable when a minority government is in office, as it must actively seek the explicit or implicit support of opposition parties to remain in power. In this context, opposition parties can use their backing on motions of confidence as leverage to influence policies. Nonetheless, even when the governing party has a majority of seats in the House of Commons, such that it is not reliant on opposition parties to remain in office, the Question Period may still allow opposition parties to steer the government’s actions in its preferred direction. Indeed, considerable energy and resources are expensed at the highest ranks of the government---in Minister's offices and among top civil servants, for instance---to prepare Cabinet ministers for the Question Period by gathering the relevant facts and ensuring that ministers can provide an answer that will content the House, the media, and the public. Ministers bear the responsibility for many policy areas, and time and attention being scarce resources, neither they nor their entourage can allocate equal or even any attention to every question under their purview. Thus, through the agenda-setting power conferred to them in the Question Period, opposition parties can shape how these scarce resources are allocated to policy areas. This influence is reinforced by the eminently public nature of the Question Period.

Like all parliamentary proceedings, the Question Period is publicly broadcast and is closely followed by the media and the public. Consequently, in addition to its role in enforcing government accountability, the Question Period is regarded by the actors involved as a public relations exercise, that is, as an opportunity to seek favorable publicity. For instance, the Question Period provides opposition parties a forum for criticizing the current government, underscoring its perceived deficiencies, and presenting an alternative course of action. Analogously, it enables the reigning party to defend its record and justify how its decisions successfully address current and salient issues. This conception of the Question Period as a public relations exercise is not entirely unrelated to its role as an accountability and monitoring mechanism since the prospect of public embarrassment can be instrumental in inducing collaboration from the government. This may be especially important when a majority government is in office, as it does not inherently fear being ousted by opposition parties.

The public nature of the Question Period may also interfere with its function as an accountability and monitoring mechanism. Instead of inducing their collaboration, the fear of public embarrassment may cause the government to avoid candidly answering a question and instead resort to obfuscation and prevarication.\footnote{The fear of public embarrassment is not the only conceivable reason for the government not to provide transparent answers to questions. For instance, the government may hold onto pertinent information from opposition parties if it is liable to weaken their support. Still, the viability of this tactic remains ambiguous, as it is likely to arouse suspicions among the opposition parties and prove ineffective against sophisticated actors.} Also, opposition parties may deliberately ask questions designed to degrade the government or to which they know the government will be reluctant to provide a forthcoming answer. This can ultimately inhibit the apparent efficacy of the Question Period as an accountability and monitoring mechanism.

\section*{A Novel Criterion for Evaluating the Efficacy of the Question Period}

Since its formal purpose is to allow members of Parliament to seek information from the government, a natural way of evaluating the Question Period’s efficacy is through the quality of the answers provided to the questions being asked. Correspondingly, a greater willingness by government ministers to offer high-quality answers to questions reflects a greater efficacy of the Question Period.

Putting in practice this seemingly simple idea proves challenging. From the outset, no formal rules govern the form and content of replies in the Question Period. More fundamentally, due to its inherently adversarial and combative nature, the Question Period legitimately is the stage of extensive debates. Thus, an answer that challenges the premises of a question is not inherently inferior, especially given that some questions are tendentious to begin. Similarly, applying a rhetorical lens to a policy issue does not automatically result in a flawed reply. Evaluating the factual accuracy of an answer is demanding and ultimately impractical, given the breadth and complexity of the issues being discussed. Also, a factually accurate answer may still be irrelevant to the initial question. Finally, when a Cabinet minister lacks familiarity with the facts relevant to a question, they should admit it, justify their inability to provide an immediate response and defer an answer rather than risk misleading the House. Therefore, what might appear to be a ``non-reply'' at first sight can be suitable in some contexts.

Given the complexities inherent in evaluating the quality of answers in the Question Period, we propose to do so based on the following criterion: a high-quality answer allows the initial question to be identified or inferred accurately. Conversely, a low-quality answer has little to no semantic relationship with the question, such that it could have been the answer to a different question or, in the worst case, any question. This conception of answer quality intrinsically reflects their relevance to questions.

This criterion overcomes many challenges associated with assessing the quality of replies in the Question Period. For instance, it allows for debate and rhetorical reframing by the government as long as it does not obscure the essence of the discussion. By contrast, this criterion captures intentional attempts by the government to divert attention away from delicate or embarrassing topics, as these efforts, to be successful, must bear no semantic relation to the initial question. Finally, this criterion does not hinge on the replies’ factual accuracy.

Admittedly, this criterion focuses on a single aspect by which answer quality manifests. It imposes a relatively minor constraint on answers in the Question Period. Many unsatisfactory replies will likely meet this standard. For instance, a reply that merely reformulates the question without offering any additional element will likely meet it. However, if a reply fails to meet this standard, its quality must be distinctly low. Put differently, this criterion reflects a necessary but insufficient condition for a high-quality answer. Consequently, this criterion is prone to inflating answer quality.

In assessing the quality of replies in the Question Period based on the criterion laid out above, it is imperative to recognize that it reflects not only the government’s incentives but also those of opposition parties. Indeed, the latter may deliberately ask questions designed to elicit low-quality answers from the government because they expect it to result in a better public posture for themselves. Thus, the quality of answers in the Question Period may be concurrently impacted by the government and the opposition’s deliberate conduct. In all cases, our measure of the quality of answers reflects the effectiveness of the Question Period as an accountability and monitoring mechanism, one of its numerous formal and informal functions.

\section*{Data and Methodology}

We analyze the exchanges in all Question Periods from the 39\textsuperscript{th} to the 43\textsuperscript{rd} legislature. This amounts to 58,343 exchanges, each containing a question and an answer. Our period of interest spans over fifteen years, from the January 23, 2006, election to the September 20, 2021, election. We focus our analysis on questions from members of the Bloc Québécois (BQ, regionalism), the Conservative Party (CPC, right-wing), the Liberal Party (LPC, center), and the New Democratic Party (NDP, left-wing). These are the only parties that have held official party status during our period of interest.\footnote{To be officially recognized, a party must have at least twelve Members of Parliament.} Our data set is derived from the official English transcripts published online by the Clerk of the House of Commons, which contain professionally translated versions of the interventions delivered in French.\footnote{The raw transcripts do not link questions to their answers, and vice-versa. To resolve this issue, we categorized all interventions from Cabinet ministers and parliamentary secretaries as answers. Subsequently, we matched each answer with the immediately preceding intervention by a member of Parliament who is neither a Cabinet minister nor a parliamentary secretary. We filtered out those exchanges consisting of a question or answer with a length below the 2.5\textsuperscript{th} percentile or above the 97.5\textsuperscript{th} percentile. We did so to eliminate interventions with unintelligible text or likely not to have been pronounced during the Question Period but were inadvertently included in our data set. These interventions are likely to be associated with low values of the answer’s quality.}

We evaluate the quality of answers in our corpus according to the criterion outlined in the previous section. We operationalize this criterion using state-of-the-art machine learning techniques. Specifically, we train an algorithm to identify which questions and answers are linked to each other based on their respective texts as accurately as possible. This algorithm is trained on the corpus of questions and answers observed in the Question Period without additional labeled data. It falls within the general class of semantic search models, which interpret a query's meaning and seek to return the value most relevant to it within a database.

\begin{figure}[!p]
    \centering
    \begin{tikzpicture}
        \draw (0,2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (D) {Distance}
        (-2,4) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (E1) {Embedding}
        (2,4) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (E2) {Embedding}
        (-2,6) node[draw, inner sep=5pt, rounded corners] (Q) {Question}
        (2,6) node[draw, inner sep=5pt, rounded corners] (A) {Answer};
        \draw[-Stealth] (Q) -- (E1) node[midway, left=5pt]{Sentence-BERT Encoder};
        \draw[-Stealth] (A) -- (E2) node[midway, right=5pt]{Sentence-BERT Encoder};
        \draw[-Stealth] (E1) -- (D);
        \draw[-Stealth] (E2) -- (D) node[midway, anchor=north west] {Cosine Similarity};
    \end{tikzpicture}
    \caption{Schematic Illustration of the Architecture of Biencoders}
    \label{fig:biencoders}
\end{figure}

More precisely, we train an artificial neural network with the following architecture: (i) the network takes as inputs an adjacency pair, that is, a question and an answer, (ii) it processes them separately through two identical encoders that convert them into numerical vectors, and (iii) it computes the distance between these vectors. This architecture is schematically illustrated in Figure \ref{fig:biencoders}. We employ a self-supervised contrastive learning objective: given a question, the model should as accurately as possible identify which answer among the answers in the training set (or a random subset thereof) is linked to the question, in the sense that the distance between the question and the possible answers is the lowest for the correct one.

\begin{figure}[!p]
    \centering
    \includegraphics{Distribution_Cosine.pdf}
    \caption{Distribution of the Cosine Similarity Between Questions and Answers}
    \label{fig:distribution}
\end{figure}

\begin{figure}[!p]
    \centering
    \begin{subfigure}[t]{0.475\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Probability_Answer_Closest.pdf}
        \caption{Probability that the Correct Answer is the Closest to the Question by Cosine Similarity Between Questions and Answers}
    \end{subfigure}    \hfill
    \begin{subfigure}[t]{0.475\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Probability_Question_Closest.pdf}
        \caption{Probability that the Correct Question is the Closest to the Answer by Cosine Similarity Between Questions and Answers}
    \end{subfigure}
    
    \bigskip
    
    \begin{subfigure}[t]{0.475\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Rank_Correct_Answer.pdf}
        \caption{Rank of the Correct Answer by Cosine Similarity Between Questions and Answers}
    \end{subfigure}    \hfill
    \begin{subfigure}[t]{0.475\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Rank_Correct_Question.pdf}
        \caption{Rank of the Correct Question by Cosine Similarity Between Questions and Answers}
    \end{subfigure}
    \caption{Validity of the Cosine Similarity Between Questions and Answers}
    \label{fig:validity_embeddings}
\end{figure}

We consider the quality of an answer in the Question Period relative to the initial question proportional to the cosine similarity between the learned representations, hereafter called the embeddings, of the question and answer. Figure \ref{fig:distribution} depicts the distribution of the cosine similarity of adjacency pairs.\footnote{A table listing the distribution’s descriptive statistics is contained in the Online Supporting Information. Note that this distribution only includes those exchanges reserved for inference.} This distribution has an approximately Gaussian shape, with a notable negative skew. This skewness suggests that, although obfuscation is not ubiquitous in the Question Period, it is nonetheless a prominent phenomenon. Indeed, a larger share of answers have a relatively low level of germaneness to initial questions, meaning that their relevance is further from the center of the distribution, compared to the share of answers with an equally high degree of pertinence. The answers with the lowest degree of germaneness are essentially orthogonal to the initial question.

Figure \ref{fig:validity_embeddings} shows that the cosine similarity between the embeddings of questions and answers reflects the probability that the embeddings of a given pair of questions and answers are found closest to one another. For an adjacency pair with a higher cosine similarity, it is more likely that: (i)~the observed answer is closest to the question among all answers, and (ii)~the observed question is closest to the answer among all questions. More generally, for a higher cosine similarity between questions and answers, there are, on average: (i)~fewer answers closer to the question than the answer that followed it, and (ii)~fewer questions closer to the answer than the question that preceded it. The Online Supporting Information contains figures showing that the accuracy of this measure is consistent across legislatures and the parties of the members of Parliament asking questions.\footnote{This is vital to rule out the possibility that the correlation between the quality of answers and variables of interest is the artifact of the model’s varying accuracy along these features.}

\begin{table}[p]
    \centering
    \caption{Five Exchanges with the Lowest Cosine Similarity Between Questions and Answers}
    \label{tab:top_pairs}
    \scriptsize
    \begin{tblr}{colspec = {X|X|c}, columns = {valign = m}, rows = {rowsep = 5pt}, row{1} = {halign = c, font = \small}}
        \hline
        \hline
        \textbf{Question} & \textbf{Answer} & \textbf{Cosine Similarity} \\
        \hline
        Mr. Speaker, the Prime Minister confirmed yesterday that Justice Grenier had the full cooperation of the federal government during his investigation. That is entirely untrue. The federal government sent a lawyer who added numerous interventions specifically to prevent careful examination of federal spending. Why did the government go to so much trouble to protect the Liberals, Conservatives and the NDP from the investigation? What are they all trying to hide? & Mr. Speaker, let us all take a look at what the new Government of Canada has achieved since coming to power. We recognized that Québeckers form a nation within a united Canada, we resolved the issue of Quebec's presence at UNESCO, we resolved the fiscal imbalance issue. This concrete and positive action demonstrates very clearly that, together, Québec and Canada are progressing just fine, thank you. & $-$0.1245 \\
        \hline
        Mr. Speaker, the current Prime Minister participated in a demonstration in 2012, when he gave his word to Aveos workers. He said, and I quote, ``It is such a shame that we have to demonstrate to ask the law and order government to obey the law.'' More recently, he said, ``It is not true that our best resources are in the ground somewhere. Our best resources are human resources.'' Is that how a prime minister keeps his word? & Mr. Speaker, I reiterate that, of course, the Government of Canada is pleased by Air Canada's announcement of its intention to purchase the Bombardier CSeries aircraft. It is a major advancement in aviation. I am certain that this addition to the Air Canada fleet will be of major benefit, both to that company and to Canada's aerospace sector across the country. & $-$0.1310 \\
        \hline
        Mr. Speaker, the Prime Minister went to China to launch free trade negotiations, but the Chinese regime had something else in mind, even though the Prime Minister did everything he could to appease China and speed up takeovers of Canadian companies by waiving security reviews. The Prime Minister clearly has zero credibility when it comes to China. How are Canadians supposed to trust this Prime Minister to act in their best interest? & Mr. Speaker, I am looking forward to answering my colleague's questions, but first I would like to congratulate the four new members who were elected last night and who will be joining us here. I also want to highlight the 24 people who stepped up across the country to put their names on ballots in the by-elections. All of us in this place know what it takes to put your name on a ballot. I congratulate all of them, and all of the volunteers who underpin the strength of our democracy. I again look forward to congratulating the four new members when they arrive in this House. This was a good day for Canada, and a good day for our democracy. & $-$0.1323 \\
        \hline
        Mr. Speaker, if the finance minister were listening to Canadians, he would know that families are getting ripped off at the bank, ripped off at the gas pump, ripped off by cellphone companies and ripped off on their cable bills. But the rip-off does not end there. The finance minister is personally ripping off taxpayers. He paid a friend \$200,000 for a 20 page speech. Does he even know that \$200,000 is the average family's income for three years? This is unjustifiable. He has no moral authority to talk about budgetary matters or anything else. Why does he not just resign? & Mr. Speaker, the hon. member would know, if he bothered to review the material, that the work done was extensive. It was done by two people over an extensive period of several months. It related to policy and communications and not as the member just suggested. It is plain that the member has not bothered to review the documentation which is publicly disclosed.	& $-$0.1485 \\
        \hline
        Mr. Speaker, it seems that ``plus ça change, plus c'est pareil.'' Over the past few months, MPs have spent hundreds of hours hearing witnesses and debating on how to fight climate change in Canada. However, it seems the Conservative government does not care if Bill C-30 is ever brought to the floor of the House. Mr. Speaker, I am asking you today to get a search warrant to see if we can find Bill C-30 and bring it back to the House because the government is not going to do it. I ask you, Mr. Speaker, if you can find it, get it back to the House so we can debate it, get it passed and fight climate change now. & Mr. Speaker, I did note the recommendation of the hon. member, that people call me on this issue. I am gathering from some recent press reports that they should be able to reach me without calling at all; I can just hear through mediums. & $-$0.1625 \\
        \hline
        \hline
    \end{tblr}
\end{table}

\begin{table}[p]
    \centering
    \caption{Five Exchanges with the Highest Cosine Similarity Between Questions and Answers}
    \label{tab:bottom_pairs}
    \scriptsize
    \begin{tblr}{colspec = {X|X|c}, columns = {valign = m}, rows = {rowsep = 5pt}, row{1} = {halign = c, font = \small}}
        \hline
        \hline
        \textbf{Question} & \textbf{Answer} & \textbf{Cosine Similarity} \\
        \hline
        Mr. Speaker, due to the efforts of our government and based on our tremendous respect for their service to our country, Canada's injured veterans may receive an average monthly benefit of between \$4,000 to \$6,000. These are supports that our injured veterans need and deserve. Can the Parliamentary Secretary to the Minister of Veterans Affairs please update this House on the benefits that our government provides to injured veterans and their families? & Mr. Speaker, I thank my hon. colleague from Wild Rose for the question and his hard work on this file. Indeed, the average monthly financial benefit that an injured veteran may be eligible for is between \$4,000 to \$6,000 a month, and in some cases injured veterans are receiving a total income that exceeds \$10,000 a month. Our government is committed to ensuring that our injured veterans and their families have the support they need and deserve. Unfortunately, the members opposite have voted against virtually every single initiative that our government has brought forward to help Canada's veterans. & 0.9542 \\
        \hline
        Mr. Speaker, Canadians gave our government a strong mandate to end the wasteful and ineffective long gun registry. My constituents have told me repeatedly that they want to see an end to this measure, which needlessly and unfairly targets law-abiding hunters, farmers and sport shooters. We see the long gun registry as no less than an attack on our way of life. Could the Minister of Public Safety please update the House on what our government is doing to address this important issue? & Mr. Speaker, I thank the member for the work that he has done on this important file. On May 2, Canadians gave the government a strong mandate to end the wasteful and ineffective long gun registry once and for all, and that is exactly what we are doing. Canadians across the country have called for this measure. For example, Michelle Vardy of the Georgian Bay Women's Outdoors Workshops and the Ontario Federation of Anglers and Hunters stated: As a woman, the long gun registry does not make me feel any safer or more secure. It is wasteful, ineffective and reduces funding to do real things. The 2 billion dollars that have already been spent would have been better used on programs like healthcare--- & 0.9507 \\
        \hline
        Mr. Speaker, the people of China and Burma are suffering terribly in the aftermath of two tragic natural disasters. Canada responded immediately with an initial \$2 million to help the people of Burma when the cyclone hit. The unparalleled devastation in Burma has brought donor countries together to aid the victims of this tragedy. Could the Minister of International Cooperation update the House on our government's commitment to the victims in Burma and China?. & Mr. Speaker, Canada is deeply saddened by the tragic loss of life and devastation resulting from the disasters in Burma and China. We share the concerns of all Canadians for the victims and their families. Today I am announcing that our government will match the contributions of Canadians to humanitarian organizations working in Burma and China. Let me assure all Canadians our government will do our share of the international effort and ensure that our help does get to the victims and their families. & 0.9452 \\
        \hline
        Mr. Speaker, Toronto police chief Mark Saunders revealed in December that 82\        \hline
        Mr. Speaker, Canada is an attractive place for African countries that are drawn by its bilingualism, its economic opportunities and its many top-notch institutions of higher learning. Last week the Prime Minister and many of his ministers were in Africa to develop new business opportunities. Could the Prime Minister please update the House on the actions our government is taking to expand trade between Ethiopia and Canada? & Mr. Speaker, I thank the member for Longueuil—Charles-LeMoyne for her question and her hard work. Expanding and diversifying trade between Canada and fast-growing African economies is a priority for our government. Trade between Canada and Ethiopia totaled \$170 million in 2018. We announced that we will be entering into negotiations towards a foreign investment promotion and protection agreement with Ethiopia, which will help further increase trade and investments for businesses in both countries. & 0.9374 \\
        \hline
        \hline
    \end{tblr}
\end{table}

To illustrate concretely what our measure of the quality of answers reflects, we present in Tables \ref{tab:top_pairs} and~\ref{tab:bottom_pairs} the five pairs of questions and answers with, respectively, the lowest and highest cosine similarity. The exchanges characterized by the lowest cosine similarity between questions and answers exemplify ways a minister may inadequately answer a question. For instance, the first two exchanges in Table \ref{tab:top_pairs} show how the minister might divert attention by underlining the government’s achievements on a tangentially related topic to suggest that the question is based on faulty assumptions or is otherwise irrelevant. As in the fourth exchange, the answer may superficially touch upon the question using ``boilerplate’’ talking points such that it may appear somewhat satisfactory when the question is known but not enough so that one could reasonably infer it. The minister may also humorously disregard the answer, as in the fifth exchange. Finally, not all failures to answer questions adequately arise manifestly from ill intent, as illustrated by the third exchange.

In contrast, the five exchanges in Table \ref{tab:bottom_pairs} contain detailed and precise answers. Many of these questions are emblematic of ``planted questions,’’ that is, pre-arranged questions asked by a backbench member of the ruling party only to provide a platform for a minister to make an announcement or highlight the government’s positive achievements. In this case, it is only natural that there is a high similarity between questions and answers. However, it is unclear how these questions, which are all but directly written by ministers to raise their profile, contribute to government accountability. This underscores the difficulty of conceptualizing answer quality and then connecting it to the various functions of the Question Period. Nevertheless, as exemplified by the fourth exchange, a high-quality answer by our standard might still challenge the question’s premises. This suggests that our conception of answer quality does not merely reflect collusion between the member who asks the question and the minister who answers it.

We now detail each component of our artificial neural network, starting with the output and moving towards the input. To begin, different metrics can be used to measure the distance between adjacency pairs' embeddings. In our network, we employ the cosine similarity, a measure reflecting the angle between two numerical vectors $\bm{x}$ and $\bm{y} \in \mathbb{R}^{n}$:
\[
    \cos\left(\bm{x}, \bm{y}\right) = \frac{\bm{x} \cdot \bm{y}}{\left \lVert \bm{x} \right \rVert \left \lVert \bm{y} \right \rVert}.
\]
By construction, the cosine similarity belongs to the interval $\left[-1,1\right]$, with two parallel vectors having a cosine similarity of $1$, two orthogonal vectors a cosine similarity of $0$, and two opposite vectors a cosine similarity of $-1$.

\begin{figure}[!tbp]
    \centering
    \makebox[\linewidth]{
    \begin{tikzpicture}
        \draw (0,0) node[draw, inner sep=5pt, rounded corners] (1) {Token 1}
        (6,0) node[draw, inner sep=5pt, rounded corners] (2) {Token 2}
        (9,0) node {...}
        (12,0) node[draw, inner sep=5pt, rounded corners] (N) {Token N}
        (0.2,2.2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
        (0.1,2.1) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
        (0,2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (A) {Self-Attention Head}
        (0,4) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (F) {Feed Forward};
        \begin{scope}[transparency group, opacity=0.25]
            \draw (6.2,2.2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
            (6.1,2.1) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
            (6,2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (A2) {Self-Attention Head};
        \end{scope}
        \draw (6,4) node[draw, inner sep=5pt, rounded corners, fill=gray!50, opacity=0.25] (F2) {Feed Forward};
        \begin{scope}[transparency group, opacity=0.25]
            \draw(12.2,2.2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
            (12.1,2.1) node[draw, inner sep=5pt, rounded corners, fill=gray!50] {Self-Attention Head}
            (12,2) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (A3) {Self-Attention Head};
        \end{scope}
        \draw (12,4) node[draw, inner sep=5pt, rounded corners, fill=gray!50, opacity=0.25] (F3) {Feed Forward};
        \draw (6,6) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (P) {Pooling}
        (6,8) node[draw, inner sep=5pt, rounded corners, fill=gray!50] (SE) {Sentence Embedding};
        \draw[-Stealth] (1) -- (A);
        \draw[-Stealth] (1) to[out=180, in=180] (F);
        \draw[-Stealth] (A) -- (F);
        \draw[-Stealth] (F) -- (P);
        \draw[-Stealth, dashed] (2) -- (A);
        \draw[-Stealth, dashed] (N) -- (A);
        \draw[-Stealth, opacity=0.25] (2) -- (A2);
        \draw[-Stealth, opacity=0.25] (2) to[out=180, in=180] (F2);
        \draw[-Stealth, opacity=0.25] (A2) -- (F2);
        \draw[-Stealth, opacity=0.25] (F2) -- (P);
        \draw[-Stealth, dashed, opacity=0.25] (1) -- (A2);
        \draw[-Stealth, dashed, opacity=0.25] (N) -- (A2);
        \draw[-Stealth, opacity=0.25] (N) -- (A3);
        \draw[-Stealth, opacity=0.25] (N) to[out=0, in=0] (F3);
        \draw[-Stealth, opacity=0.25] (A3) -- (F3);
        \draw[-Stealth, opacity=0.25] (F3) -- (P);
        \draw[-Stealth, dashed, opacity=0.25] (1) -- (A3);
        \draw[-Stealth, dashed, opacity=0.25] (2) -- (A3);

        \draw[-Stealth] (P) -- (SE);
    \end{tikzpicture}}
    \caption{Schematic Illustration of the Architecture of Sentence-BERT Encoders}
    \label{fig:BERT}
\end{figure}

The embeddings of questions and answers are derived from a variant of BERT called ``Sentence-BERT'' \citep{devlin-etal-2019-bert, reimers2019sentencebert}. Due to their prominence in natural language processing, in general, and our methodology, in particular, we describe the architecture of BERT encoders in detail.\footnote{We encourage those interested in a more detailed or formal treatment to consult \citet{learning_deep_learning}, \citet{pml1Book}, or \citet{zhang2023dive}.} The architecture of a Sentence-BERT encoder is schematically illustrated in Figure \ref{fig:BERT}, in which the branch processing Token 1 is highlighted, and the other branches are faded. An encoder takes a sentence or short paragraph as input or, formally, an ordered sequence of strings of characters, called tokens, representing words or parts of words. Each token is associated with a numerical vector. Token-level embeddings are added to positional embeddings, reflecting each token’s relative location within the input sequence. The resulting numerical vectors are then passed through multiple identical layers, each consisting of a multi-head self-attention mechanism and a feed-forward component. The multi-head self-attention mechanism is the central component of this architecture. A self-attention head considers both the embedding of the token being processed and the embeddings of the surrounding tokens. It allows BERT to develop a contextual understanding of each token and, especially, to recognize what in the context is pertinent to its meaning. Concretely, the self-attention head outputs a weighted sum of all the input embeddings computed according to adjustable weights. In each layer, multiple self-attention heads operate in parallel, justifying the term ``multi-head self-attention.’’ The output of the multi-head self-attention, along with the initial embedding, is passed to a fully connected layer that applies to it a linear transformation and a non-linear activation function. In the end, the BERT encoder outputs for each input token a numerical vector. Sentence embeddings are computed by pooling---for instance, by averaging---these vectors. This is what differentiates Sentence-BERT from plain BERT.

Consistently with best practices in natural language processing, we employ transfer learning to train our artificial neural network \citep{ruder-etal-2019-transfer, Laurer_van_Atteveldt_Casas_Welbers_2024}. Rather than initiating the training process with random parameters, we begin with estimates from another model pre-trained to perform general tasks on a large corpus distinct from ours, which we ``fine-tune’’ to our specific needs.\footnote{Alternatively, we could have directly used the embeddings from the pre-trained model before any fine-tuning. The risk with this approach is that the pre-trained model could ascribe a poor quality to some answers simply because it is unfamiliar with the Question Period and not necessarily because they are irrelevant to the questions. Instead, we seek to understand how well a model generally familiar with the Question Period can accurately infer the initial question from the text of its answer.} Fine-tuning consists of further updating the pre-trained model’s parameters at a lower learning rate than during the pre-training process to improve its accuracy on our corpus and specific task. The pre-trained model we use is designed for: (i)~missing token prediction---that is, to predict randomly masked words in short sentences and paragraphs---on a large corpus of general text, and (ii) semantic search on a large dataset of 215 million pairs of adjacency pairs from various online forums.\footnote{Since its publication, BERT has given birth to many variants. They all adhere to the architecture described here, based on the Transformer encoder, but differ in their training regimen. The pre-training procedure outlined here pertains specifically to RoBERTa \citep{liu2019roberta}. The original BERT’s pre-training procedure also involves next-sentence prediction. Our pre-trained model is grounded on MPNet, which employs a distinctive strategy for missing token prediction \citep{MPNet}. In brief, this approach deviates from BERT and RoBERTa in the information based on which the network performs missing token prediction.} Although this pre-trained model is not tailored to our domain, it provides representations capturing general language patterns, such as semantic similarities or context-dependent ambiguities between words in various domains, and a general understanding of semantic search. Using this prior knowledge accelerates the learning of our embeddings. The resulting representations are also more general and flexible, which improves their performance on documents outside the training set.

The model is fine-tuned on a five percent subset of all exchanges in our corpus. One percent of exchanges are set aside as a validation set to optimize the model's training hyperparameters. The remaining 94\\[
    \text{MRR} = \frac{1}{\left|Q\right|} \sum_{i = 1}^{\left|Q\right|} \frac{1}{\text{Rank}_{i}}.
\]

It is standard to assimilate to zero all ranks below some threshold. Accordingly, we truncate all ranks below ten. The Online Supporting Information contains the value of the mean reciprocal rank of the validation set for various values of the batch size and epoch and the training hyperparameters we retained.

\section*{The Correlates of the Quality of Answers in the Question Period}

Having measured the quality of answers in the Question Period, we seek to explore its relationship with other variables. The goal is to demonstrate the dependability and value of our measurement approach. Our focus is directed at two specific questions.

First, we consider the correlation between the quality of answers and the balance of power in the House of Commons, defined as whether the governing party holds a majority of seats. We conjecture that when the government has a minority of seats, its answers will have, on average, a higher level of relevance. Generally, a minority government has more incentives to cooperate with opposition parties than a majority government. The reason is that when the governing party does not hold a majority of seats, it must actively seek support from opposition parties to withstand motions of confidence and remain in power. In this context, failing to answer questions from opposition members of Parliament diligently can aggravate them, adversely impacting their inclination to support the government, even if only tacitly, and ultimately weakening the latter’s survival prospects.

This supposed relationship between the quality of answers and the balance of power may be reflected differently in the government’s replies to questions from different parties. The government might be more inclined to cooperate with parties it perceives as closer to its ideology. For instance, this may lead the Liberal Party to be more responsive to questions from the New Democratic Party than to questions from the Conservative Party. Also, the pertinence of the answers elicited by opposition parties may vary with their relative representation in the House, although the direction of this effect is ambiguous. On the one hand, a higher representation in the House may enhance an opposition party’s ability to elicit satisfactory answers from government ministers since it benefits from a higher numerical influence on the outcome of motions of confidence. On the other hand, a higher representation in the House might put this party in more direct and immediate competition with the government, especially to the extent that it reflects popular support, driving it to be more assertive and combative in questioning the government and, parallelly, increasing the latter’s circumspection in replying to its questions. This dynamic may also occur when the government has a majority in the House of Commons.

Second, we investigate the variations in the quality of answers associated with the initial question’s topic. Numerous factors may contribute to the government’s reluctance to reply to questions about some topics. For instance, personal integrity is a topic that, when challenged, can be very embarrassing and damaging to one's honor and reputation. In this context, government ministers may decide to prevaricate rather than address allegations directly to avoid fueling the controversy or risking giving opposition parties more ammunition. These incentives affect all ministers regardless of their partisan affiliation.

The inclination of government ministers to answer questions about some issues may also vary with their party affiliation. In particular, we expect government ministers to provide more relevant answers about issues over which their party holds a more favorable reputation. Over time, parties gain a reputation as better stewards of some policy issues based on their perceived expertise, the popularity of their positions, or the relative importance of the topic to their supporter base \citep{petrocik_1996, BELANGER2008477, egan_2013}. Colloquially, we say that parties come to ``own’’ some issues. Accordingly, parties tend to strategically avoid drawing attention to matters over which they have a weaker reputation since doing so would underscore their opponents’ strengths and undermine their position. Instead, parties tend to emphasize issues they own, and one way to do so is by providing more detailed and forthcoming answers to questions about those issues. Note that issue ownership is likely to be reflected in the topics of the questions as well: all else equal, opposition parties likely will ask more questions about issues they own to increase their salience.\footnote{The relationship between a party’s ideological proximity with the government and the quality of the answers to questions emanating from its members may be mediated, at least partly, by the government’s varying inclination to answer questions about different topics. Indeed, members of a party closer ideologically to the government may tend to inquire about topics over which the government is more comfortable responding.}

\begin{figure}[!tbp]
    \centering
    \includegraphics{Issue_Ownership.pdf}
    \caption{Reputation of Political Parties over Policy Issues}
    \label{fig:issue_ownership}
\end{figure}

To appreciate the relative reputation of Canadian political parties on policy issues, we consider responses to the question ``Which party would do the best job at handling each of the following issues?'' in the Canadian Election Study’s last three editions \citep{CES_2019, CES_2021}.\footnote{Although previous research has been devoted to issue ownership in Canadian politics, it has examined a period anterior to our period of interest, particularly before the founding of the contemporary Conservative Party of Canada \citep{belanger_2003}. Therefore, it does not convey information immediately relevant to the current configuration of the Canadian party system.} The policy issues considered in all three editions are the following: Crime and Justice, Defense, Education, Environment, Healthcare, Immigration and Minorities, and International Diplomacy. The distribution of responses is depicted in Figure~\ref{fig:issue_ownership}. The relative standing of parties on policy issues varies over time. Nevertheless, between the Conservative Party and the Liberal Party, the former has consistently enjoyed a relatively better reputation for Crime and Justice and Defense. In contrast, the latter has a better reputation for Education, Environment, Healthcare, Immigration and Minorities, and International Diplomacy.

To conclude, we emphasize the impossibility of establishing a causal relationship between the quality of answers and variables of interest. This must be reflected in the interpretation of our results. We must also bear in mind that questions are endogenous. For instance, they may be purposefully formulated to elicit low- or high-quality answers. Consequently, the quality of answers reflects not only the incentives of the government but also the intentions of opposition parties, which may go beyond eliciting relevant and insightful answers.

\section*{Results}

\subsection*{Relationship Between the Quality of Answers and the Balance of Power in the House of Commons}

\begin{figure}[!bp]
    \centering
    \includegraphics{Cosine_by_Party_and_Legislature.pdf}
    \caption{Average Cosine Similarity Between Questions and Answers by Party and Legislature}
    \label{fig:cosine_by_legislature}
\end{figure}

Figure \ref{fig:cosine_by_legislature} illustrates the evolution of the average cosine similarity between questions and answers based on the party affiliation of the questioning member across the five legislatures within our period of interest. For context, the Conservative Party was in power between the 39\textsuperscript{th} and 41\textsuperscript{st} legislatures, whereas the Liberal Party held office during the 42\textsuperscript{nd} and 43\textsuperscript{rd} legislatures. Also, note that minority governments held office during the 39\textsuperscript{th}, 40\textsuperscript{th}, and 43\textsuperscript{rd} legislatures.

We draw four observations from this figure. First, answers to questions from backbench government members have, on average, a remarkably higher quality than answers to questions from opposition members of Parliament. This was partly anticipated since members of the reigning party are unlikely to ask questions that would embarrass or hurt the government they belong to. Anecdotally, it is common for ministerial aides to ``plant questions,’’ that is, to arrange for backbench government members to ask friendly questions, allowing ministers to promote the government’s positive achievements or to criticize opposition parties. This observation gives credence to the perception that this is a widespread practice. Still, the difference in the relevance of answers to questions from backbench government members and opposition members of Parliament is extraordinary relative to the difference in the quality of answers to questions from members of different opposition parties.

Second, there is mixed evidence about the hypothesized relationship between the relevance of answers in the Question Period and the balance of power. Comparing the 39\textsuperscript{th} and 40\textsuperscript{th} legislatures to the 41\textsuperscript{st}, it appears that the Conservative Party offered, on average, more relevant answers to questions from the opposition when it held a majority of seats in the House of Commons, contrary to our hypothesis. On the other hand, contrasting the 42\textsuperscript{nd} and 43\textsuperscript{rd} legislatures, we find that the Liberal Party offered, on average, more relevant answers to questions from the opposition when it held a minority of seats in the House of Commons. However, the 43\textsuperscript{rd} legislature coincided with the COVID-19 pandemic, which has likely affected the nature of the questions asked by the opposition and the government’s inclination to answer them in a forthcoming way. Given this ambiguous evidence, we do not consider our hypothesis to be confirmed by the data.

Third, third-party members receive, on average, more relevant answers to their questions than members of the official opposition. Indeed, during the 39\textsuperscript{th}, 40\textsuperscript{th}, 42\textsuperscript{nd}, and 43\textsuperscript{rd} legislatures, the relevance of answers to questions from members of third parties was significantly higher than the relevance of answers to questions from members of the official opposition. This can be further appreciated by concentrating on outcomes in the 41\textsuperscript{st} legislature, the first and only time the New Democratic Party formed the official opposition. Over that period, there was no meaningful difference between the quality of answers to questions from members of the New Democratic Party and the Liberal Party. In contrast, there were statistically significant differences during the previous two legislatures. This difference can be reasonably ascribed to the fact that the official opposition tends to be regarded by the media and public as the ``government-in-waiting’’ and, as such, is in direct competition with the government. This can lead the official opposition to be more antagonistic and forceful in questioning the government and the latter to be more hostile and reserved in answering its questions.

Fourth, we note that the difference between answers to questions from the official opposition and third parties is much smaller than the difference between answers to questions from different opposition parties attributable to their perceived ideological proximity to the government. For instance, during the 42\textsuperscript{nd} and 43\textsuperscript{rd} legislatures, questions from members of the New Democratic Party have, on average, received much more relevant answers than questions from members of all opposition parties before and over the same period. This relationship was stronger during the 43\textsuperscript{rd} legislature since the Liberal Party held a minority of seats in the House of Commons and heavily relied on the New Democratic Party to survive motions of confidence. Note that during that period, the representation of the NDP in the House of Commons was comparable to its representation during the 39\textsuperscript{th} and 40\textsuperscript{th} legislatures and the Liberal Party’s during the 41\textsuperscript{st} legislature, so the difference cannot be ascribed to variations in the relative weight of the New Democratic Party in the House.

\subsection*{Relationship Between the Topic of Questions and the Quality of Answers}

Studying variations in answer quality based on the questions' topic demands a way of modeling the latter. This can be approached in various ways. One involves examining variations in the quality of answers across the portfolios of the ministers answering questions. Portfolios gather all ministers associated with a government department. It is imperative to recognize that the government controls who answers each question. Indeed, this is one way the government can attempt to evade or apply a rhetorical frame to the debate. For instance, a question about pipeline construction could be answered by either the Minister of the Environment or the Minister of Natural Resources, depending on which angle the government wishes to put forward. These deliberate choices can meaningfully impact our results.

\begin{figure}[!tbp]
    \centering
    \includegraphics[width=\linewidth]{Cosine_by_Party_and_Portfolio.pdf}
    \caption{Average Cosine Similarity Between Questions and Answers by Party and Portfolio}
    \label{fig:cosine_by_portfolio}
\end{figure}

Figure \ref{fig:cosine_by_portfolio} depicts the results of this approach. Specifically, it illustrates the average cosine similarity between questions and answers by party and portfolio of the members of the government who answered the question. To neutralize the systematic differences between parties’ willingness to answer questions, the figure displays the difference with the average cosine similarity between questions and answers for all questions answered by a given party.

There are only a few statistically significant differences between the Conservative and Liberal parties in the average cosine similarity between questions and answers given the answering minister’s portfolio. In particular, the cosine similarity between questions and answers was higher when the Conservative Party was in office for the following portfolios: Government House Leader, National Revenue, Public Safety and Emergency Preparedness, and Veterans Affairs. On the other hand, the cosine similarity between questions and answers was higher when the Liberal Party was in power for the following portfolios: Agriculture and Agri-Food, Employment, Labor and Social Development, International Development, Justice, Public Services and Procurement, and Transport, Infrastructure and Communities.

These differences are generally consistent with our hypothesis about the relationship between answer quality and issue ownership. With the Conservative Party enjoying a better reputation over crime and justice and the Liberal Party over international diplomacy, we expected ministers and parliamentary secretaries from corresponding portfolios to deliver, on average, higher-quality answers. Other statistically significant differences are consistent with the stated priorities of the parties. We think especially of the Liberal Party’s greater inclination to answer questions related to the Transport, Infrastructure, and Communities portfolio. This is not shocking given that the Liberal Party came into power following a high-profile promise of increasing public infrastructure investments by \$60 billion over ten years, focusing on affordable housing, green infrastructure, public transit, and rural communities.

An alternative approach to modeling the topic of the initial questions is to estimate it using topic models. Topic models are statistical models employed in natural language processing to cluster documents in a corpus similar in semantic structure. Since the resulting labels are estimated solely using the text of the questions, they are not susceptible to manipulation by the government. To carry out this approach, we employ BERTopic, a topic modeling algorithm leveraging sentence embeddings to create dense clusters representing easily interpretable topics \citep{grootendorst2022bertopic}.\footnote{Default parameter values were used for estimating topics, except for the minimum topic size, which we set to 50. Topic labels were generated with an open-source Llama 2 chat model \citep{touvron2023llama}. The prompt used to do so is presented in the Online Supporting Information.}

\begin{figure}[!p]
    \centering
    \includegraphics[width=\linewidth]{Topics_CPC_Llama.pdf}
    \caption{Topics with the 20 Lowest and Highest Average Cosine Similarity Between Questions and Answers for the Conservative Party}
    \label{fig:topics_CPC}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=\linewidth]{Topics_LPC_Llama2.pdf}
    \caption{Topics with the 20 Lowest and Highest Average Cosine Similarity Between Questions and Answers for the Liberal Party}
    \label{fig:topics_LPC}
\end{figure}

Figures \ref{fig:topics_CPC} and \ref{fig:topics_LPC} depict the average cosine similarity between questions and answers given the initial question’s topic as estimated by BERTopic for the periods during which the Conservative and Liberal parties held office, respectively. Only the 20 themes associated with the lowest and the highest average cosine similarity are displayed in the figures. For reference, the average cosine similarity between questions and answers for the corresponding party is labeled by a dashed vertical line in both figures. In addition to their implications for the hypothetical relationship between the initial questions’ topic and the answers’ quality, these figures offer a rich overview of the themes discussed in the Question Period.

We begin our discussion of these figures by considering the topics characterized by a low cosine similarity between questions and answers. There are many parallels---in fact, more similarities than dissimilarities---among the themes associated with the least relevant answers for the Conservative and Liberal parties. Most are not directly related to policy issues but what one could reasonably consider trivia. As we had conjectured, questions disputing government ministers’ integrity and rectitude systematically receive the lowest-quality answers. Specifically, topics related to allegedly broken promises, conflicts of interest, corruption, ethics, government advertising, inappropriate expenses, lobbying, political fundraising, and transparency rank among the bottom 20 topics in the average cosine similarity between questions and answers for both parties. Relatedly, a topic grouping the questions in which a member of Parliament asks a Cabinet member to apologize for their alleged inappropriate behavior is among those associated with the lowest-quality answers for both parties. Among policy-related topics, budget deficits, foreign investments, jobs and unemployment, natural security, and taxes are among those with the 20 lowest average cosine similarities between questions and answers for both parties. This suggests that these policy issues are equally delicate for the Conservative and Liberal parties to address.

The topics with the highest average cosine similarity between questions and answers are characterized by many more differences between the Conservative and Liberal parties, yet with some unexpected similarities. We identify among the 20 topics with the highest average cosine similarity between questions and answers issues that parties are distinctly perceived to ``own,’’ as we had postulated. In particular, the Conservative Party has provided some of its most relevant answers to questions about agriculture, criminal justice, international trade, natural resources, public safety, and veterans. Analogously, climate change, housing, infrastructure, mental health, poverty, relations with Indigenous communities, and seniors are among the topics to which the Liberal Party has provided the most relevant answers. More generally, topics with the highest average cosine similarity between questions and answers for the Liberal Party have a social bent, consistent with the long-lasting perception that the Liberal Party has a relatively solid reputation over social policy issues. Unexpectedly, many of the top topics for the Conservative Party are linked to foreign policy, including humanitarian aid and refugee settlement, in contrast with the Liberal Party, even though the latter enjoys a better general reputation over those issues. Among the topics with the highest average cosine similarity between questions and answers for both parties, we find health care, gun control, and vaccines (against H1N1 for the Conservative Party and COVID-19 for the Liberal Party). This is startling, especially regarding the first two topics, given that the Conservative and Liberal parties have different, almost opposite, approaches to them.

\section*{Discussion and Conclusion}

In this paper, we study the quality of answers during the Question Period in the Canadian House of Commons. To evaluate the quality of answers, we propose a novel measurement approach inspired by semantic search, a central task in information retrieval and natural language processing. In particular, we measure answer quality based on how well the initial question can be accurately identified from the text of its answer. This conception of answer quality inherently reflects the pertinence of answers to initial questions. It is particularly relevant in evaluating the efficacy of the Question Period as an accountability and monitoring mechanism. A noteworthy advantage of this approach is that it can be operationalized computationally by fine-tuning a large language model on the corpus of observed questions and answers with no additional labeled data. This makes our method especially suited to analyzing large corpora.

Our innovative measurement approach uncovers some correlates of the quality of answers in the Question Period. We find that answer quality varies significantly based on the party to which the member of Parliament asking the question belongs. Answers to questions from backbench members of the ruling party, members of third parties, and members of parties closer ideologically to the government have, on average, a better quality. We also find a meaningful correlation between answer quality and the topic of the initial questions. On this point, we identify a surprising degree of similarities between both parties that held office during our period of interest. For instance, the themes characterized by the lowest cosine similarity between questions and answers for both parties include allegedly broken promises, budget deficits, corruption allegations, expense scandals, foreign investments, government advertising, jobs and unemployment, lobbying activities, natural security, political fundraising, supposed conflicts of interest, and taxes. Besides, questions about health care, gun control, and vaccines are associated with some of the highest-quality answers from both parties. However, we also uncover evidence that answer quality is significantly related to issue ownership. Indeed, many of the questions associated with the highest quality of answers are about issues over which the party in government has a noticeably stronger reputation than other parties.

The measurement approach introduced in this paper can be applied with minimal adaptation to other contexts, both in and outside political science. The practicality of extending this approach to comparable institutions is evident. As mentioned in the Introduction, many legislatures have institutions akin to the Question Period, with famous examples including Prime Minister’s Questions in the United Kingdom and ``Questions au Gouvernment’’ in France. Despite their central role in ensuring government accountability to Parliament, these institutions have not been sufficiently studied. Furthermore, an accurate assessment of the efficacy of these institutions requires a measure of the quality of answers, a crucial variable for which researchers have lacked a suitable tool until now. The proposed methodology may also find resonance in other political contexts. For instance, it could be employed to analyze congressional hearings, election debates, and press conferences, including in the United States. Beyond political science, this approach could be used to scrutinize news interviews by public figures other than politicians, press conferences by central bankers, or investor calls by public company executives. The versatility of our innovative approach makes apparent its relevance and impact.

To conclude, despite generating significant interest, large language models have not yet established themselves as a staple of political science research \citep{linegar_2023}. Our study showcases their value in investigating vital questions within political science. Specifically, these models proved instrumental in generating valuable insights into central instruments of political accountability and representation within parliamentary systems. We urge political scientists to delve deeper into the potential of large language models to expose fresh perspectives in other crucial areas of study.

\clearpage

\printbibliography

\end{document}
